{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ddfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "\n",
    "# --- Core Libraries ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Database & System Libraries ---\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- Import Custom DB Connector ---\n",
    "from common.database.MQSDBConnector import MQSDBConnector\n",
    "\n",
    "# --- Notebook Configuration ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Configure logging for better debugging and tracing.\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported and MQSDBConnector ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc252e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Loading and Preparation\n",
    "\n",
    "# --- 1. Instantiate DB Connector ---\n",
    "db_connector = MQSDBConnector()\n",
    "\n",
    "# --- 2. Define Data Fetching Function ---\n",
    "\n",
    "# Define the SQL query template\n",
    "# This query must be customized to select your 14 predictive variables (X)\n",
    "# and your 1 outcome variable (Y) from your database.\n",
    "MARKET_DATA_QUERY = \"\"\"\n",
    "    SELECT \n",
    "        timestamp,\n",
    "        -- outcome_variable (e.g., future_1q_volatility),\n",
    "        -- predictive_variable_1 (e.g., trailing_1m_volatility),\n",
    "        -- predictive_variable_2 (e.g., implied_volatility),\n",
    "        -- ...\n",
    "        -- predictive_variable_14 (e.g., debt_to_gdp)\n",
    "    FROM \n",
    "        your_aggregated_data_table\n",
    "    WHERE \n",
    "        timestamp::date BETWEEN %s AND %s\n",
    "        -- Add any other conditions (e.g., specific asset class)\n",
    "    ORDER BY\n",
    "        timestamp;\n",
    "\"\"\"\n",
    "\n",
    "def get_market_data(db, lookback_days) -> pd.DataFrame:\n",
    "    \"\"\"Fetches and processes market data for the RBP model.\"\"\"\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(days=lookback_days)\n",
    "    \n",
    "    # This query assumes your data is already in a wide format (one row per timestamp)\n",
    "    # as required by the RBP model.\n",
    "    sql = MARKET_DATA_QUERY\n",
    "    params = [start_time.date(), end_time.date()]\n",
    "    \n",
    "    logging.info(f\"Fetching data from {start_time.date()} to {end_time.date()}...\")\n",
    "    result = db.execute_query(sql, params, fetch=True) # Use fetch=True\n",
    "\n",
    "    if result['status'] != 'success' or not result.get('data'):\n",
    "        logging.error(\"Failed to fetch data or no data returned.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(result['data'])\n",
    "    logging.info(f\"Successfully fetched {len(df)} rows.\")\n",
    "\n",
    "    # --- Data Processing ---\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.set_index('timestamp')\n",
    "    \n",
    "    # Convert all columns to numeric, handling potential errors\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Drop rows where critical data might be missing\n",
    "    df.dropna(inplace=True) \n",
    "    \n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "# --- 3. Fetch Data ---\n",
    "# model_lookback_days = 365 * 20 # ~20 years of data\n",
    "# all_data = get_market_data(db_connector, model_lookback_days)\n",
    "\n",
    "# --- 4. Define Variables and Split Data ---\n",
    "# 'all_data' should now be your wide-format DataFrame\n",
    "# with all variables ready for the model.\n",
    "\n",
    "# outcome_variable = 'your_Y_variable_column_name' \n",
    "# predictive_variables = [\n",
    "#     'var_1_col_name', 'var_2_col_name', 'var_3_col_name',\n",
    "#     'var_4_col_name', 'var_5_col_name', 'var_6_col_name', \n",
    "#     'var_7_col_name', 'var_8_col_name', 'var_9_col_name',\n",
    "#     'var_10_col_name', 'var_11_col_name', 'var_12_col_name',\n",
    "#     'var_13_col_name', 'var_14_col_name'\n",
    "# ]\n",
    "\n",
    "# --- Split Data ---\n",
    "# [cite_start]The paper uses a fixed training and testing split [cite: 536-539]\n",
    "# training_start = '1986-03-31'\n",
    "# training_end = '2004-12-31'\n",
    "# testing_start = '2005-03-31'\n",
    "# testing_end = '2023-12-31'\n",
    "\n",
    "# X_train = all_data.loc[training_start:training_end, predictive_variables]\n",
    "# y_train = all_data.loc[training_start:training_end, outcome_variable]\n",
    "# X_test = all_data.loc[testing_start:testing_end, predictive_variables]\n",
    "# y_test = all_data.loc[testing_start:testing_end, outcome_variable]\n",
    "\n",
    "# print(f\"Training data shape (X, y): {X_train.shape}, {y_train.shape}\")\n",
    "# print(f\"Testing data shape (X, y): {X_test.shape}, {y_test.shape}\")\n",
    "# print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Pre-computation on Training Data\n",
    "\n",
    "# --- Compute Historical Averages and Covariance ---\n",
    "# These are computed ONCE on the training data.\n",
    "# These values (x_mean, inv_cov_matrix) are fundamental for all\n",
    "# Mahalanobis distance calculations.\n",
    "\n",
    "def compute_training_statistics(X_train_df):\n",
    "  # [cite_start]1. Calculate the mean vector (x-bar) of the training variables [cite: 149]\n",
    "  #   x_mean = X_train_df.mean().values\n",
    "  #\n",
    "  # 2. Calculate the covariance matrix (Omega) of the training variables\n",
    "  #   cov_matrix = X_train_df.cov().values\n",
    "  #\n",
    "  # [cite_start]3. Calculate the inverse covariance matrix (Omega-inverse) [cite: 149]\n",
    "  #   This is the key component for Mahalanobis distance\n",
    "  #   inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "  #\n",
    "  #   return x_mean, inv_cov_matrix, X_train_df.columns.tolist()\n",
    "  pass\n",
    "\n",
    "# --- Store Stats ---\n",
    "# We compute this for the *full* set of variables.\n",
    "# Inside the grid, we will re-compute this for *subsets* of variables.\n",
    "# full_train_stats = {\n",
    "#     'x_mean': ...,\n",
    "#     'inv_cov': ...,\n",
    "#     'vars': ...\n",
    "# } = compute_training_statistics(X_train)\n",
    "\n",
    "# print(\"Training statistics (mean, inv_cov) computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Core Helper Functions (Relevance)\n",
    "\n",
    "# These functions implement the core math from the paper.\n",
    "\n",
    "def calculate_mahalanobis_distance(vec1, vec2, inv_cov_matrix):\n",
    "  \"\"\"Calculates the squared Mahalanobis distance.\"\"\"\n",
    "  # diff = vec1 - vec2\n",
    "  # return diff @ inv_cov_matrix @ diff.T\n",
    "  pass\n",
    "\n",
    "def calculate_relevance(x_i, x_t, x_mean, inv_cov_matrix):\n",
    "  \"\"\"\n",
    "  Calculates the relevance of a past observation (x_i) to a\n",
    "  [cite_start]current prediction task (x_t), based on Equation 1[cite: 141].\n",
    "  \"\"\"\n",
    "\n",
    "  # [cite_start]1. Similarity (sim) component, Equation 2 [cite: 142]\n",
    "  #   sim_component = calculate_mahalanobis_distance(x_i, x_t, inv_cov_matrix)\n",
    "  #\n",
    "  # [cite_start]2. Informativeness of past observation (info(x_i)), Equation 3 [cite: 143]\n",
    "  #   info_i = calculate_mahalanobis_distance(x_i, x_mean, inv_cov_matrix)\n",
    "  #\n",
    "  # [cite_start]3. Informativeness of current task (info(x_t)), Equation 4 [cite: 144]\n",
    "  #   info_t = calculate_mahalanobis_distance(x_t, x_mean, inv_cov_matrix)\n",
    "  #\n",
    "  # [cite_start]4. Total Relevance (r_it), Equation 1 [cite: 141]\n",
    "  #   r_it = (-0.5 * sim_component) + 0.5 * (info_i + info_t)\n",
    "  #   return r_it\n",
    "  pass\n",
    "\n",
    "print(\"Relevance helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16944366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Core Helper Functions (Prediction & Fit)\n",
    "\n",
    "def get_relevance_for_task(x_t, X_train, y_train, x_mean, inv_cov):\n",
    "  \"\"\"\n",
    "  Calculates relevance scores for ALL past observations (x_i)\n",
    "  against a SINGLE current task (x_t).\n",
    "  \"\"\"\n",
    "  # 1. Iterate through each row (x_i) in X_train\n",
    "  # 2. Call calculate_relevance(x_i, x_t, ...) for each\n",
    "  # 3. Return a pandas Series of relevance scores, indexed by X_train.index\n",
    "  pass\n",
    "\n",
    "def calculate_prediction_weights(relevance_scores, r_threshold_quantile):\n",
    "  \"\"\"\n",
    "  Calculates observation weights (w_it) based on relevance\n",
    "  [cite_start]and a censoring threshold, per Equations 7-9 [cite: 169-173].\n",
    "  \"\"\"\n",
    "  # [cite_start]1. Determine the relevance threshold value (r*) [cite: 169]\n",
    "  #   r_star = relevance_scores.quantile(r_threshold_quantile)\n",
    "  #\n",
    "  # [cite_start]2. Identify retained (delta=1) and censored (delta=0) observations [cite: 169]\n",
    "  #   retained_mask = relevance_scores >= r_star\n",
    "  #\n",
    "  # [cite_start]3. Calculate n, N, phi, r_sub_avg, etc. [cite: 175-176]\n",
    "  #\n",
    "  # [cite_start]4. Calculate the scaling factor (lambda^2) [cite: 173]\n",
    "  #\n",
    "  # [cite_start]5. Calculate final weights (w_it_retained) for all i [cite: 169]\n",
    "  #    (Censored observations will have a different weight calculation)\n",
    "  # 6. Return the final vector of weights (w_it)\n",
    "  pass\n",
    "\n",
    "def calculate_fit(weights, outcomes):\n",
    "  \"\"\"\n",
    "  Calculates the Fit for a prediction task, which is the\n",
    "  [cite_start]squared correlation of relevance weights and outcomes, per Eq. 11[cite: 198].\n",
    "  \"\"\"\n",
    "  # 1. Calculate Pearson correlation: rho = np.corrcoef(weights, outcomes)[0, 1]\n",
    "  # 2. Return rho**2\n",
    "  pass\n",
    "\n",
    "def calculate_asymmetry(weights, outcomes, retained_mask):\n",
    "  \"\"\"\n",
    "  [cite_start]Calculates asymmetry per Equation 13[cite: 213].\n",
    "  \"\"\"\n",
    "  # [cite_start]1. Create weights for retained subsample (w_t_plus) [cite: 210]\n",
    "  # [cite_start]2. Create weights for censored subsample (w_t_minus) [cite: 210]\n",
    "  # 3. Calculate rho(w_t_plus, y) and rho(w_t_minus, y)\n",
    "  # 4. Return 0.5 * (rho_plus - rho_minus)**2\n",
    "  pass\n",
    "\n",
    "def calculate_adjusted_fit(fit, asymmetry, K):\n",
    "  \"\"\"\n",
    "  [cite_start]Calculates adjusted fit per Equation 14[cite: 219].\n",
    "  K is the number of predictive variables in this calibration.\n",
    "  \"\"\"\n",
    "  # return K * (fit + asymmetry)\n",
    "  pass\n",
    "\n",
    "print(\"Prediction and Fit helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: The Grid Prediction Loop (Single Task)\n",
    "\n",
    "# --- This is the core of RBP ---\n",
    "# We process ONE prediction task (x_t) at a time.\n",
    "# We build a grid of predictions and adjusted fits.\n",
    "\n",
    "def process_grid_for_one_task(x_t, X_train, y_train):\n",
    "  \"\"\"\n",
    "  Builds the entire prediction grid (Exhibit 1) for a\n",
    "  [cite_start]single prediction task (x_t) [cite: 221-222].\n",
    "  \"\"\"\n",
    "\n",
    "  # --- 1. Define the Grid ---\n",
    "  # [cite_start]Columns: All combinations of variables [cite: 221]\n",
    "  # (e.g., from 1 var up to K vars. This can be 2^K - 1)\n",
    "  # variable_combinations = get_variable_combinations(X_train.columns)\n",
    "  # [cite_start]To save time, the paper uses a \"sparse sampling\" method [cite: 544]\n",
    "  #\n",
    "  # [cite_start]Rows: Relevance thresholds (e.g., 0, 0.2, 0.5, 0.8) [cite: 221, 541]\n",
    "  # relevance_thresholds = [0.0, 0.2, 0.5, 0.8]\n",
    "  #\n",
    "  # --- 2. Initialize Grid Results ---\n",
    "  # grid_results = [] # Store (cell_params, prediction, adjusted_fit)\n",
    "  #\n",
    "  # --- 3. Iterate through Grid Cells (theta) ---\n",
    "  # for var_combo in variable_combinations:\n",
    "  #   K = len(var_combo)\n",
    "  #\n",
    "  #   # --- 3a. Setup for this Variable Subset ---\n",
    "  #   X_train_sub = X_train[var_combo]\n",
    "  #   x_t_sub = x_t[var_combo]\n",
    "  #\n",
    "  #   # Re-compute stats for this *subset*\n",
    "  #   x_mean_sub, inv_cov_sub, _ = compute_training_statistics(X_train_sub)\n",
    "  #\n",
    "  #   # Get relevance scores for this task, using this subset\n",
    "  #   relevance_scores = get_relevance_for_task(\n",
    "  #       x_t_sub, X_train_sub, y_train, x_mean_sub, inv_cov_sub\n",
    "  #   )\n",
    "  #\n",
    "  #   for r_thresh in relevance_thresholds:\n",
    "  #     # --- 3b. Process this Cell (theta) ---\n",
    "  #     cell_params = {'vars': var_combo, 'thresh': r_thresh}\n",
    "  #\n",
    "  #     # 1. Get prediction weights\n",
    "  #     weights, mask = calculate_prediction_weights(relevance_scores, r_thresh)\n",
    "  #\n",
    "  #     # 2. Get cell prediction (y_hat_theta)\n",
    "  #     y_hat_theta = np.sum(weights * y_train)\n",
    "  #\n",
    "  #     # 3. Get cell reliability\n",
    "  #     fit = calculate_fit(weights, y_train)\n",
    "  #     asymmetry = calculate_asymmetry(weights, y_train, mask)\n",
    "  #     adj_fit = calculate_adjusted_fit(fit, asymmetry, K)\n",
    "  #\n",
    "  #     [cite_start]# 4. Store cell results [cite: 222]\n",
    "  #     grid_results.append((cell_params, y_hat_theta, adj_fit))\n",
    "  #\n",
    "  # return pd.DataFrame(grid_results, columns=['params', 'prediction', 'adj_fit'])\n",
    "  pass\n",
    "\n",
    "# --- Test the function with the first task ---\n",
    "# x_t_example = X_test.iloc[0]\n",
    "# grid_for_task_0 = process_grid_for_one_task(x_t_example, X_train, y_train)\n",
    "#\n",
    "# print(\"Grid results for one task:\")\n",
    "# print(grid_for_task_0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcd12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Composite Prediction and RBI (Single Task)\n",
    "\n",
    "# --- Calculate Final Prediction ---\n",
    "\n",
    "def calculate_composite_prediction(grid_df):\n",
    "  \"\"\"\n",
    "  Forms the composite grid prediction (y_hat_grid)\n",
    "  [cite_start]per Equations 15 and 16 [cite: 225-230].\n",
    "  \"\"\"\n",
    "  # 1. Get all adjusted fits\n",
    "  #   adj_fits = grid_df['adj_fit']\n",
    "  #\n",
    "  # [cite_start]2. Calculate reliability weights (psi_theta), Eq. 15 [cite: 228]\n",
    "  #   Ensure all fits are non-negative, or handle as needed\n",
    "  #   sum_adj_fits = adj_fits[adj_fits > 0].sum()\n",
    "  #   psi_weights = adj_fits / sum_adj_fits\n",
    "  #   psi_weights = psi_weights.fillna(0)\n",
    "  #\n",
    "  # 3. Calculate composite prediction (y_hat_grid), Eq. [cite_start]16 [cite: 230]\n",
    "  #   y_hat_grid = np.sum(psi_weights * grid_df['prediction'])\n",
    "  #\n",
    "  #   return y_hat_grid, psi_weights\n",
    "  pass\n",
    "\n",
    "# y_hat_grid_0, psi_weights_0 = calculate_composite_prediction(grid_for_task_0)\n",
    "# print(f\"Composite Prediction for Task 0: {y_hat_grid_0}\")\n",
    "\n",
    "# --- Calculate RBI ---\n",
    "\n",
    "def calculate_rbi_for_task(grid_df, all_variables):\n",
    "  \"\"\"\n",
    "  Calculates RBI for every variable for a single task,\n",
    "  [cite_start]using the grid results per Equation 18[cite: 375].\n",
    "  \"\"\"\n",
    "  # rbi_scores = {}\n",
    "  #\n",
    "  # for var_k in all_variables:\n",
    "  #   [cite_start]# 1. Find cells *with* var_k (delta_k(theta) = 1) [cite: 375]\n",
    "  #     includes_k_mask = grid_df['params'].apply(lambda p: var_k in p['vars'])\n",
    "  #     adj_fit_with_k = grid_df.loc[includes_k_mask, 'adj_fit']\n",
    "  #\n",
    "  #   [cite_start]# 2. Find cells *without* var_k (delta_k(theta) = 0) [cite: 375]\n",
    "  #     excludes_k_mask = ~includes_k_mask\n",
    "  #     adj_fit_without_k = grid_df.loc[excludes_k_mask, 'adj_fit']\n",
    "  #\n",
    "  #   [cite_start]# 3. Calculate weighted average difference (per Eq. 18) [cite: 375, 382]\n",
    "  #   # This is a simplified interpretation:\n",
    "  #   # avg_fit_with_k = adj_fit_with_k.mean()\n",
    "  #   # avg_fit_without_k = adj_fit_without_k.mean()\n",
    "  #   # rbi_k = avg_fit_with_k - avg_fit_without_k\n",
    "  #\n",
    "  #   # NOTE: Eq. 18 is more complex, involving scaling (alpha_theta)\n",
    "  #   [cite_start]# and specific denominators[cite: 377, 383].\n",
    "  #   # A full implementation would need to build those weights.\n",
    "  #\n",
    "  #   rbi_scores[var_k] = rbi_k\n",
    "  #\n",
    "  # return pd.Series(rbi_scores)\n",
    "  pass\n",
    "\n",
    "# rbi_scores_0 = calculate_rbi_for_task(grid_for_task_0, predictive_variables)\n",
    "# print(\"RBI Scores for Task 0:\")\n",
    "# print(rbi_scores_0.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Batch Processing (All Tasks)\n",
    "\n",
    "# --- Loop RBP & RBI for all tasks in the test set ---\n",
    "\n",
    "# results = []\n",
    "#\n",
    "# [cite_start]# Iterate over each prediction task in the test set [cite: 539]\n",
    "# for index, x_t in X_test.iterrows():\n",
    "#   # 1. Process the grid for this task\n",
    "#   grid_df = process_grid_for_one_task(x_t, X_train, y_train)\n",
    "#\n",
    "#   # 2. Calculate the composite prediction\n",
    "#   y_hat_grid, _ = calculate_composite_prediction(grid_df)\n",
    "#\n",
    "#   # 3. Calculate the RBI scores for this task\n",
    "#   rbi_scores = calculate_rbi_for_task(grid_df, predictive_variables)\n",
    "#\n",
    "#   # 4. Store results\n",
    "#   results.append({\n",
    "#       'task_date': index,\n",
    "#       'y_actual': y_test.loc[index],\n",
    "#       'y_pred_grid': y_hat_grid,\n",
    "#       'rbi_scores': rbi_scores\n",
    "#   })\n",
    "#\n",
    "# # --- Format Results ---\n",
    "# # results_df = pd.DataFrame(results)\n",
    "# # rbi_df = pd.DataFrame(\n",
    "# #     [r['rbi_scores'] for r in results], index=[r['task_date'] for r in results]\n",
    "# # )\n",
    "#\n",
    "# print(\"Batch processing complete.\")\n",
    "# print(\"RBI DataFrame Head:\")\n",
    "# print(rbi_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7611c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Comparison: Linear Regression (t-statistic)\n",
    "\n",
    "# --- Run a standard OLS regression on the training data ---\n",
    "# [cite_start]This is to get the t-statistics for comparison[cite: 417].\n",
    "\n",
    "def get_ols_t_stats(X_train, y_train):\n",
    "  \"\"\"\n",
    "  Runs a single OLS regression and returns the t-statistics\n",
    "  for all variables.\n",
    "  \"\"\"\n",
    "  # 1. Add a constant (intercept) to the model\n",
    "  #   X_with_const = sm.add_constant(X_train)\n",
    "  #\n",
    "  # 2. Fit the OLS model\n",
    "  #   model = sm.OLS(y_train, X_with_const).fit()\n",
    "  #\n",
    "  # [cite_start]3. Extract t-statistics (and drop the 'const' row) [cite: 419]\n",
    "  #   t_stats = model.tvalues.drop('const', errors='ignore')\n",
    "  #\n",
    "  # [cite_start]4. Return the absolute t-stats for ranking [cite: 547]\n",
    "  #   return t_stats.abs().sort_values(ascending=False)\n",
    "  pass\n",
    "\n",
    "# ols_t_stats = get_ols_t_stats(X_train, y_train)\n",
    "# print(\"--- OLS t-statistics (Absolute) ---\")\n",
    "# print(ols_t_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ebf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Analysis & Visualization\n",
    "\n",
    "# [cite_start]--- 1. Aggregate Importance Comparison (like Exhibit 7) [cite: 554] ---\n",
    "# We need to calculate the informativeness-weighted average RBI\n",
    "# (the tau-statistic) [cite_start]across all tasks [cite: 437-438].\n",
    "\n",
    "def calculate_informativeness(X, x_mean, inv_cov):\n",
    "  [cite_start]\"\"\"Calculates info(x, x-bar) for all rows in X, per Eq. 3/4 [cite: 143-144].\"\"\"\n",
    "  # 1. Iterate over X, call calculate_mahalanobis_distance(x, x_mean, inv_cov)\n",
    "  # 2. Return a Series of info scores\n",
    "  pass\n",
    "\n",
    "# --- Calculate info-weighted RBI ---\n",
    "# info_scores_test = calculate_informativeness(\n",
    "#     X_test, full_train_stats['x_mean'], full_train_stats['inv_cov']\n",
    "# )\n",
    "# info_weights = info_scores_test / info_scores_test.sum()\n",
    "# average_rbi = rbi_df.multiply(info_weights, axis=0).sum()\n",
    "\n",
    "# --- Create comparison table ---\n",
    "# comparison_df = pd.DataFrame({\n",
    "#     't_statistic': ols_t_stats,\n",
    "#     'info_weighted_rbi': average_rbi\n",
    "# })\n",
    "# print(\"--- Aggregate Importance Comparison ---\")\n",
    "# print(comparison_df.sort_values(by='info_weighted_rbi', ascending=False))\n",
    "\n",
    "\n",
    "# [cite_start]--- 2. Prediction-Specific RBI Heatmap (like Exhibit 8 & 10) [cite: 559, 612] ---\n",
    "# This is the key visualization showing RBI's power.\n",
    "\n",
    "# plt.figure(figsize=(20, 8))\n",
    "# # We must normalize (standardize) the RBI scores *across time* (by row)\n",
    "# # or *across variables* (by column) to make the colors comparable.\n",
    "# # Let's standardize by variable (column-wise)\n",
    "#\n",
    "# # rbi_normalized = (rbi_df - rbi_df.mean()) / rbi_df.std()\n",
    "#\n",
    "# # sns.heatmap(\n",
    "# #     rbi_normalized.transpose(),\n",
    "# [cite_start]#     cmap='vlag', # 'vlag' is a good red-white-blue colormap [cite: 559]\n",
    "# #     center=0\n",
    "# # )\n",
    "# # plt.title(\"Prediction-Specific Variable Importance (RBI) Heatmap\")\n",
    "# # plt.xlabel(\"Prediction Task (Date)\")\n",
    "# # plt.ylabel(\"Predictive Variable\")\n",
    "# # plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
