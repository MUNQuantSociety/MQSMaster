{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a54b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\simanta\\anaconda3\\lib\\site-packages (4.53.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\simanta\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\simanta\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: torch in c:\\users\\simanta\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\simanta\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\simanta\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\simanta\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: jupyter in c:\\users\\simanta\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\simanta\\anaconda3\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: notebook in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter) (7.2.2)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter) (5.5.1)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter) (6.28.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter) (7.8.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (8.27.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter) (3.6.6)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter) (3.0.43)\n",
      "Requirement already satisfied: pygments in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter) (2.15.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from notebook->jupyter) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from notebook->jupyter) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from notebook->jupyter) (4.2.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from notebook->jupyter) (0.2.3)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (305.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.4.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter) (0.27.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.1)\n",
      "Requirement already satisfied: executing in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: fqdn in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.1)\n",
      "Requirement already satisfied: uri-template in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\simanta\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.2.3)\n"
     ]
    }
   ],
   "source": [
    "# First install required libraries if not already done\n",
    "!pip install transformers datasets scikit-learn torch pandas matplotlib seaborn jupyter kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce449cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"ankurzing/sentiment-analysis-for-financial-news\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Define file path\n",
    "file_path = os.path.join(path, \"all-data.csv\")\n",
    "\n",
    "# Read CSV with no header and proper encoding\n",
    "df = pd.read_csv(file_path, engine='python', sep=',', header=None, encoding='latin-1')\n",
    "\n",
    "# Check the first few rows to understand column order\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Assign column names manually based on inspection\n",
    "# Based on public dataset info, it's usually [sentiment, text]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Now filter valid labels\n",
    "valid_labels = {'positive', 'neutral', 'negative'}\n",
    "df['label'] = df['label'].str.strip()\n",
    "df = df[df['label'].isin(valid_labels)]\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: print shapes\n",
    "print(\"\\nTrain shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"  # FinBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Convert pandas DataFrames to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Define your label mappings correctly (only the valid ones)\n",
    "labels = ['positive', 'neutral', 'negative']\n",
    "\n",
    "# Create mappings\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Map string labels to integers within the tokenization function\n",
    "    # Ensure examples['label'] is a string before mapping\n",
    "    label_str = examples[\"label\"]\n",
    "    examples[\"labels\"] = label2id[label_str]\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=False)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "# Remove the original 'label' column as we now have 'labels'\n",
    "tokenized_train = tokenized_train.remove_columns([\"label\"])\n",
    "tokenized_test = tokenized_test.remove_columns([\"label\"])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels), # Use len(labels) to be dynamic\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finbert-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"finbert-finetuned-final\")\n",
    "tokenizer.save_pretrained(\"finbert-finetuned-final\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "true_labels = tokenized_test[\"labels\"]\n",
    "\n",
    "# Define the list of all possible labelsac\n",
    "all_labels = list(label2id.values())\n",
    "\n",
    "# Print report\n",
    "print(classification_report(true_labels, preds, target_names=label2id.keys(), labels=all_labels, zero_division=0))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(true_labels, preds, labels=all_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label2id.keys())\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"FinBERT Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 1. Load your custom model\n",
    "model_path = \"finbert-finetuned-final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# 2. Fetch news from FMP with proper error handling\n",
    "def fetch_news(symbol, api_key, days=3730):\n",
    "    cutoff = datetime.utcnow() - timedelta(days=days)\n",
    "    all_articles = []\n",
    "    page = 0\n",
    "\n",
    "    while True:\n",
    "        url = f\"https://financialmodelingprep.com/api/v3/stock_news?symbol={symbol}&page={page}&apikey={api_key}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            news = response.json()\n",
    "\n",
    "            if not news:\n",
    "                break  # No more articles\n",
    "\n",
    "            # Filter articles by date\n",
    "            page_articles = []\n",
    "            for article in news:\n",
    "                try:\n",
    "                    article_date = datetime.strptime(article['publishedDate'], \"%Y-%m-%d %H:%M:%S\")\n",
    "                    if article_date < cutoff:\n",
    "                        continue  # Skip articles older than cutoff\n",
    "                    page_articles.append(article)\n",
    "                except (KeyError, ValueError):\n",
    "                    continue\n",
    "\n",
    "            all_articles.extend(page_articles)\n",
    "\n",
    "            # Check if we've reached the cutoff date\n",
    "            if len(page_articles) < len(news):\n",
    "                break  # This page contained articles beyond cutoff date\n",
    "\n",
    "            page += 1\n",
    "\n",
    "            # Safety limit to prevent infinite loops\n",
    "            if page > 50:  # Max 50 pages (50,000 articles)\n",
    "                print(\"Reached maximum page limit\")\n",
    "                break\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching page {page}: {e}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Found {len(all_articles)} articles within {days} days\")\n",
    "    return all_articles\n",
    "\n",
    "# 3. Analyze sentiment with YOUR model\n",
    "def analyze_sentiment(articles):\n",
    "    results = []\n",
    "    for art in articles:\n",
    "        try:\n",
    "            # Use title if content is missing\n",
    "            text = art.get('content', art.get('title', ''))\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            inputs = tokenizer(text,\n",
    "                              return_tensors=\"pt\",\n",
    "                              truncation=True,\n",
    "                              max_length=512)\n",
    "            with torch.no_grad():\n",
    "                logits = model(**inputs).logits\n",
    "            probs = torch.softmax(logits, dim=1)[0]\n",
    "\n",
    "            results.append({\n",
    "                'date': datetime.strptime(art['publishedDate'], \"%Y-%m-%d %H:%M:%S\").date(),\n",
    "                'sentiment': probs[0].item() - probs[2].item(),  # positive - negative\n",
    "                'title': art['title'],\n",
    "                'source': art.get('site', 'Unknown')\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article '{art.get('title', '')}': {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 4. Fetch stock prices with error handling\n",
    "def fetch_prices(symbol, api_key):\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{symbol}?apikey={api_key}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Check if response contains historical data\n",
    "        if 'historical' not in data:\n",
    "            print(f\"No price data found: {data}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        prices = pd.DataFrame(data['historical'])\n",
    "        prices['date'] = pd.to_datetime(prices['date'])\n",
    "        return prices[['date', 'close']]\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch prices: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 5. Main workflow\n",
    "API_KEY = \"API_KEY_HERE\"  # Replace with your actual API key\n",
    "SYMBOL = \"AAPL\"\n",
    "\n",
    "# Fetch and process data\n",
    "print(\"Fetching news...\")\n",
    "news = fetch_news(SYMBOL, API_KEY, days=3507)\n",
    "print(f\"Found {len(news)} articles\")\n",
    "\n",
    "print(\"Analyzing sentiment...\")\n",
    "sentiment_df = analyze_sentiment(news)\n",
    "print(f\"Processed {len(sentiment_df)} articles\")\n",
    "\n",
    "print(\"Fetching stock prices...\")\n",
    "prices_df = fetch_prices(SYMBOL, API_KEY)\n",
    "print(f\"Found {len(prices_df)} price records\")\n",
    "\n",
    "if sentiment_df.empty or prices_df.empty:\n",
    "    print(\"Insufficient data for visualization\")\n",
    "else:\n",
    "    # Aggregate daily sentiment\n",
    "    daily_sentiment = sentiment_df.groupby('date')['sentiment'].mean().reset_index()\n",
    "    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "\n",
    "    # Merge with prices\n",
    "    merged_df = pd.merge(\n",
    "        prices_df,\n",
    "        daily_sentiment,\n",
    "        on='date',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Filter to the period where we have sentiment data\n",
    "    sentiment_start = daily_sentiment['date'].min()\n",
    "    sentiment_end = daily_sentiment['date'].max()\n",
    "    chart_start = sentiment_start - timedelta(days=30)\n",
    "    chart_end = sentiment_end + timedelta(days=5)\n",
    "\n",
    "    filtered_df = merged_df[\n",
    "        (merged_df['date'] >= chart_start) &\n",
    "        (merged_df['date'] <= chart_end)\n",
    "    ]\n",
    "\n",
    "    # Fill missing sentiment with 0 (neutral)\n",
    "    filtered_df['sentiment'].fillna(0, inplace=True)\n",
    "\n",
    "    # Add rolling average for sentiment\n",
    "    filtered_df['sentiment_ma'] = filtered_df['sentiment'].rolling(7, min_periods=1).mean()\n",
    "\n",
    "    # 6. Visualization - single plot with dual axes\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    # Plot stock prices\n",
    "    ax1.plot(filtered_df['date'], filtered_df['close'], 'b-', linewidth=2, label='Stock Price')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Stock Price', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.set_title(f'{SYMBOL} Stock Price vs. News Sentiment')\n",
    "\n",
    "    # Create second axis for sentiment\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot sentiment rolling average\n",
    "    ax2.plot(filtered_df['date'], filtered_df['sentiment_ma'],\n",
    "            'r-', linewidth=2,\n",
    "            label='7-day Sentiment Avg')\n",
    "    ax2.set_ylabel('Sentiment Score (7-day MA)', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "\n",
    "    # Add horizontal line at 0 for neutral sentiment\n",
    "    ax2.axhline(0, color='gray', linestyle='--', linewidth=0.8, label='Neutral')\n",
    "\n",
    "    # Add markers for the actual sentiment period\n",
    "    ax2.axvline(sentiment_start, color='g', linestyle=':', alpha=0.7, label='Sentiment Start')\n",
    "    ax2.axvline(sentiment_end, color='r', linestyle=':', alpha=0.7, label='Sentiment End')\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Show sample of the most positive/negative news\n",
    "    print(\"\\nTop 3 Positive News:\")\n",
    "    print(sentiment_df.nlargest(3, 'sentiment')[['date', 'title', 'sentiment']])\n",
    "\n",
    "    print(\"\\nTop 3 Negative News:\")\n",
    "    print(sentiment_df.nsmallest(3, 'sentiment')[['date', 'title', 'sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Required columns check ---\n",
    "required_price_cols = {'date', 'close'}\n",
    "required_sentiment_cols = {'date', 'sentiment'}\n",
    "\n",
    "if prices_df.empty or sentiment_df.empty:\n",
    "    raise ValueError(\"Error: One or both of the input DataFrames (prices_df, sentiment_df) are empty.\")\n",
    "\n",
    "if not required_price_cols.issubset(prices_df.columns):\n",
    "    raise ValueError(f\"Error: prices_df is missing required columns: {required_price_cols - set(prices_df.columns)}\")\n",
    "\n",
    "if not required_sentiment_cols.issubset(sentiment_df.columns):\n",
    "    raise ValueError(f\"Error: sentiment_df is missing required columns: {required_sentiment_cols - set(sentiment_df.columns)}\")\n",
    "\n",
    "# --- Convert date columns and inspect ---\n",
    "prices_df['date'] = pd.to_datetime(prices_df['date'])\n",
    "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
    "\n",
    "print(\"Latest price date:\", prices_df['date'].max().date())\n",
    "print(\"Latest sentiment date:\", sentiment_df['date'].max().date())\n",
    "\n",
    "# --- Merge DataFrames ---\n",
    "sentiment_daily = sentiment_df.groupby('date')['sentiment'].mean().reset_index()\n",
    "merged_df = pd.merge(prices_df, sentiment_daily, on='date', how='left')\n",
    "merged_df['sentiment'] = merged_df['sentiment'].fillna(0)\n",
    "\n",
    "if merged_df.empty:\n",
    "    raise ValueError(\"Error: Merged DataFrame is empty.\")\n",
    "if merged_df['close'].isnull().all():\n",
    "    raise ValueError(\"Error: All close prices are NaN after merge.\")\n",
    "\n",
    "# --- Compute indicators ---\n",
    "def compute_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def prepare_df(df):\n",
    "    df = df.copy()\n",
    "    df['sentiment_ma'] = df['sentiment'].rolling(7, min_periods=1).mean()\n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['sma_5'] = df['close'].rolling(5).mean()\n",
    "    df['rsi'] = compute_rsi(df['close'])\n",
    "    df.ffill(inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = prepare_df(merged_df)\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(\"Last date in df before forecast:\", df['date'].iloc[-1].date())\n",
    "\n",
    "# --- Generate features ---\n",
    "def make_features(df, lookback=5):\n",
    "    scaler = MinMaxScaler()\n",
    "    features = ['close', 'sentiment_ma', 'returns', 'sma_5', 'rsi']\n",
    "    data = scaler.fit_transform(df[features])\n",
    "    \n",
    "    X, y, date_out = [], [], []\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    for i in range(lookback, len(df)):\n",
    "        X.append(data[i-lookback:i])\n",
    "        y.append(data[i, 0])\n",
    "        date_out.append(df['date'].iloc[i])\n",
    "        \n",
    "    return np.array(X), np.array(y), scaler, pd.Series(date_out).reset_index(drop=True)\n",
    "\n",
    "X, y, scaler, dates = make_features(df)\n",
    "\n",
    "if len(X) == 0 or len(y) == 0:\n",
    "    raise ValueError(\"Error: Not enough data after lookback window.\")\n",
    "\n",
    "# --- LSTM model ---\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden=50):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "# --- Training ---\n",
    "def train_model(X, y):\n",
    "    X, y = torch.tensor(X).float(), torch.tensor(y).float().view(-1, 1)\n",
    "    tr_len = int(0.8 * len(X))\n",
    "    X_tr, y_tr, X_te, y_te = X[:tr_len], y[:tr_len], X[tr_len:], y[tr_len:]\n",
    "    model = StockLSTM(X.shape[2])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for e in range(50):\n",
    "        model.train(); optimizer.zero_grad()\n",
    "        loss = loss_fn(model(X_tr), y_tr)\n",
    "        loss.backward(); optimizer.step()\n",
    "        if e % 10 == 0:\n",
    "            print(f\"Epoch {e}, Loss: {loss.item():.4f}\")\n",
    "    return model, model(X_te).detach().numpy(), y_te.numpy(), X_te\n",
    "\n",
    "model, preds, actual, X_test = train_model(X, y)\n",
    "\n",
    "# --- Forecasting ---\n",
    "def forecast_days(model, seq, days, n_feat, scaler):\n",
    "    preds = []\n",
    "    for _ in range(days):\n",
    "        with torch.no_grad():\n",
    "            val = model(torch.tensor(seq).float().unsqueeze(0)).item()\n",
    "        padded = np.array([[val] + [0]*(n_feat-1)])\n",
    "        unscaled = scaler.inverse_transform(padded)[0,0]\n",
    "        preds.append(unscaled)\n",
    "        seq = np.vstack([seq[1:], padded])\n",
    "    return preds\n",
    "\n",
    "forecast = forecast_days(model, X[-1], 7, X.shape[2], scaler)\n",
    "forecast_start = df['date'].iloc[-1] + timedelta(days=1)\n",
    "\n",
    "print(\"Forecasting starts from:\", forecast_start.date())\n",
    "print(\"\\nForecast for Next 7 Days:\")\n",
    "for i, val in enumerate(forecast):\n",
    "    print(f\"{(forecast_start + timedelta(days=i)).date()}: ${val:.2f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "# SYMBOL is from previous cell\n",
    "a_inv = scaler.inverse_transform(np.hstack([actual.reshape(-1,1), np.zeros((len(actual), X.shape[2]-1))]))[:,0]\n",
    "p_inv = scaler.inverse_transform(np.hstack([preds, np.zeros((len(preds), X.shape[2]-1))]))[:,0]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(dates[-len(a_inv):], a_inv, label=\"Actual\")\n",
    "plt.plot(dates[-len(p_inv):], p_inv, label=\"Predicted\")\n",
    "plt.title(f\"{SYMBOL} - LSTM Forecast (Latest data: {df['date'].iloc[-1].date()})\")\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Price\")\n",
    "plt.xticks(rotation=45); plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
