{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987a54b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (4.53.2)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/eb/62/eb8157afb21bd229c864521c1ab4fa8e9b4f1b06bafdd8c4668a7a31b5dd/datasets-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/15/fa/c61a787e35f05f17fc10523f567677ec4eeee5f95aa4798dbbbcd9625617/scikit_learn-1.7.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.7.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (3.10.3)\n",
      "Collecting seaborn\n",
      "  Obtaining dependency information for seaborn from https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl.metadata\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jupyter\n",
      "  Obtaining dependency information for jupyter from https://files.pythonhosted.org/packages/38/64/285f20a31679bf547b75602702f7800e74dbabae36ef324f716c02804753/jupyter-1.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting kagglehub\n",
      "  Obtaining dependency information for kagglehub from https://files.pythonhosted.org/packages/49/bf/c2a24567bb6bd80c1fe7cb2ed1a332666476f69c313256aff96094bef93e/kagglehub-0.3.12-py3-none-any.whl.metadata\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Obtaining dependency information for pyarrow>=15.0.0 from https://files.pythonhosted.org/packages/71/30/f3795b6e192c3ab881325ffe172e526499eb3780e306a15103a2764916a2/pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Obtaining dependency information for dill<0.3.9,>=0.3.0 from https://files.pythonhosted.org/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl.metadata\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/7c/e4/56027c4a6b4ae70ca9de302488c5ca95ad4a39e190093d6c1a8ace08341b/requests-2.32.4-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/d9/6b/1c443fe6cfeb4ad1dcf231cdec96eb94fb43d6498b4469ed8b51f8b59a37/xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Obtaining dependency information for multiprocess<0.70.17 from https://files.pythonhosted.org/packages/0a/7d/a988f258104dcd2ccf1ed40fdc97e26c4ac351eeaf81d76e266c52d84e2f/multiprocess-0.70.16-py312-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<=2025.3.0,>=2023.1.0 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]<=2025.3.0,>=2023.1.0 from https://files.pythonhosted.org/packages/56/53/eb690efa8513166adef3e0669afd31e95ffde69fb3c52ec2ac7223ed6018/fsspec-2025.3.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.8.0 from https://files.pythonhosted.org/packages/ea/b5/29fece1a74c6a94247f8a6fb93f5b28b533338e9c34fdcc9cfe7a939a767/scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/7d/4f/1195bbac8e0c2acc5f740661631d8d750dc38d4a32b23ee5df3cde6f4e0d/joblib-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Collecting notebook (from jupyter)\n",
      "  Obtaining dependency information for notebook from https://files.pythonhosted.org/packages/b3/c0/e64d2047fd752249b0b69f6aee2a7049eb94e7273e5baabc8b8ad05cc068/notebook-7.4.4-py3-none-any.whl.metadata\n",
      "  Downloading notebook-7.4.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Obtaining dependency information for jupyter-console from https://files.pythonhosted.org/packages/ca/77/71d78d58f15c22db16328a476426f7ac4a60d3a5a7ba3b9627ee2f7903d4/jupyter_console-6.6.3-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Obtaining dependency information for nbconvert from https://files.pythonhosted.org/packages/cc/9a/cd673b2f773a12c992f41309ef81b99da1690426bd2f96957a7ade0d3ed7/nbconvert-7.16.6-py3-none-any.whl.metadata\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter) (6.29.5)\n",
      "Collecting ipywidgets (from jupyter)\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/58/6a/9166369a2f092bd286d24e6307de555d63616e8ddb373ebad2b5635ca4cd/ipywidgets-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Obtaining dependency information for jupyterlab from https://files.pythonhosted.org/packages/f8/82/66910ce0995dbfdb33609f41c99fe32ce483b9624a3e7d672af14ff63b9f/jupyterlab-4.4.4-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab-4.4.4-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for aiohttp!=4.0.0a0,!=4.0.0a1 from https://files.pythonhosted.org/packages/98/d5/7ac2464aebd2eecac38dbe96148c9eb487679c512449ba5215d233755582/aiohttp-3.12.14-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (9.4.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter)\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.14 from https://files.pythonhosted.org/packages/ca/51/5447876806d1088a0f8f71e16542bf350918128d0a69437df26047c8e46f/widgetsnbextension-4.0.14-py3-none-any.whl.metadata\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter)\n",
      "  Obtaining dependency information for jupyterlab_widgets~=3.0.15 from https://files.pythonhosted.org/packages/43/6a/ca128561b22b60bd5a0c4ea26649e68c8556b82bc70a0c396eebc977fe86/jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter-console->jupyter) (3.0.51)\n",
      "Requirement already satisfied: pygments in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter-console->jupyter) (2.19.2)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for async-lru>=1.0.0 from https://files.pythonhosted.org/packages/03/49/d10027df9fce941cb8184e78a02857af36360d33e1721df81c5ed2179a1a/async_lru-2.0.5-py3-none-any.whl.metadata\n",
      "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for httpx>=0.25.0 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyter-lsp>=2.0.0 from https://files.pythonhosted.org/packages/47/7c/12f68daf85b469b4896d5e4a629baa33c806d61de75ac5b39d8ef27ec4a2/jupyter_lsp-2.2.6-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_lsp-2.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyter-server<3,>=2.4.0 from https://files.pythonhosted.org/packages/46/1f/5ebbced977171d09a7b0c08a285ff9a20aafb9c51bde07e52349ff1ddd71/jupyter_server-2.16.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyterlab-server<3,>=2.27.1 from https://files.pythonhosted.org/packages/54/09/2032e7d15c544a0e3cd831c51d77a8ca57f7555b2e1b2922142eddb02a84/jupyterlab_server-2.27.3-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for notebook-shim>=0.2 from https://files.pythonhosted.org/packages/f9/33/bd5b9137445ea4b680023eb0469b2bb969d61303dedb2aac6560ff3d14a1/notebook_shim-0.2.4-py3-none-any.whl.metadata\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for beautifulsoup4 from https://files.pythonhosted.org/packages/50/cd/30110dc0ffcf3b131156077b90e9f60ed75711223f306da4db08eff8403b/beautifulsoup4-4.13.4-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach[css]!=5.0.0 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for bleach[css]!=5.0.0 from https://files.pythonhosted.org/packages/fc/55/96142937f66150805c25c4d0f31ee4132fd33497753400734f9dfdcbdc66/bleach-6.2.0-py3-none-any.whl.metadata\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for defusedxml from https://files.pythonhosted.org/packages/07/6c/aa3f2f849e01cb6a001cd8554a88d4c77c5c1a31c95bdf1cf9301e6d9ef4/defusedxml-0.7.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for jupyterlab-pygments from https://files.pythonhosted.org/packages/b1/dd/ead9d8ea85bf202d90cc513b533f9c363121c7792674f78e0d8a854b63b4/jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for mistune<4,>=2.0.3 from https://files.pythonhosted.org/packages/01/4d/23c4e4f09da849e127e9f123241946c23c1e30f45a88366879e064211815/mistune-3.1.3-py3-none-any.whl.metadata\n",
      "  Downloading mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for nbclient>=0.5.0 from https://files.pythonhosted.org/packages/34/6d/e7fa07f03a4a7b221d94b4d586edb754a9b0dc3c9e2c93353e9fa4e0d117/nbclient-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for pandocfilters>=1.4.1 from https://files.pythonhosted.org/packages/ef/af/4fbc8cab944db5d21b7e2a5b8e9211a03a79852b1157e2c102fcc61ac440/pandocfilters-1.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.5.0 from https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for aiosignal>=1.4.0 from https://files.pythonhosted.org/packages/fb/76/641ae371508676492379f16e2fa48f4e2c11741bd63c48be4b12a6b09cba/aiosignal-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/0b/15/c026e9a9fc17585a9d461f65d8593d281fedf55fbf7eb53f16c6df2392f9/frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/6a/a3/0fbc7afdf7cb1aa12a086b02959307848eb6bcc8f66fcb66c0cb57e2a2c1/multidict-6.6.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/19/61/d582be5d226cf79071681d1b46b848d6cb03d7b70af7063e33a2787eaa03/propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/eb/83/5d9092950565481b413b31a23e75dd3418ff0a277d6e0abf3729d4d1ce25/yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "     ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 76.3/76.3 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting webencodings (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Obtaining dependency information for webencodings from https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Obtaining dependency information for tinycss2<1.5,>=1.1.0 from https://files.pythonhosted.org/packages/e6/34/ebdc18bae6aa14fbee1a08b63c015c72b64868ff7dae68808ab500c492e2/tinycss2-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for anyio from https://files.pythonhosted.org/packages/a1/ee/48ca1a7c89ffec8b6a0c5d02b89c305671d5ffd8d3c94acf8b8c408575bb/anyio-4.9.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for h11>=0.16 from https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (310)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for argon2-cffi>=21.1 from https://files.pythonhosted.org/packages/4f/d3/a8b22fa575b297cd6e3e3b0155c7e25db170edf1c74783d6a31a2490b8d9/argon2_cffi-25.1.0-py3-none-any.whl.metadata\n",
      "  Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyter-events>=0.11.0 from https://files.pythonhosted.org/packages/e2/48/577993f1f99c552f18a0428731a755e06171f9902fa118c379eb7c04ea22/jupyter_events-0.12.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyter-server-terminals>=0.4.4 from https://files.pythonhosted.org/packages/07/2d/2b32cdbe8d2a602f697a649798554e4f072115438e92249624e532e8aca6/jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for overrides>=5.0 from https://files.pythonhosted.org/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl.metadata\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for prometheus-client>=0.9 from https://files.pythonhosted.org/packages/32/ae/ec06af4fe3ee72d16973474f122541746196aaa16cea6f66d18b963c6177/prometheus_client-0.22.1-py3-none-any.whl.metadata\n",
      "  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pywinpty>=2.0.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for pywinpty>=2.0.1 from https://files.pythonhosted.org/packages/88/e5/9714def18c3a411809771a3fbcec70bffa764b9675afb00048a620fca604/pywinpty-2.0.15-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pywinpty-2.0.15-cp312-cp312-win_amd64.whl.metadata (5.2 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for send2trash>=1.8.2 from https://files.pythonhosted.org/packages/40/b0/4562db6223154aa4e22f939003cb92514c79f3d4dccca3444253fd17f902/Send2Trash-1.8.3-py3-none-any.whl.metadata\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for terminado>=0.8.3 from https://files.pythonhosted.org/packages/6a/9e/2064975477fdc887e47ad42157e214526dcad8f317a948dee17e1659a62f/terminado-0.18.1-py3-none-any.whl.metadata\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for websocket-client>=1.7 from https://files.pythonhosted.org/packages/5a/84/44687a29792a70e111c5c477230a72c4b957d88d16141199bf9acb7537a3/websocket_client-1.8.0-py3-none-any.whl.metadata\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for babel>=2.10 from https://files.pythonhosted.org/packages/b7/b8/3fe70c75fe32afc4bb507f75563d39bc5642255d1d94f1f23604725780bf/babel-2.17.0-py3-none-any.whl.metadata\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for json5>=0.9.0 from https://files.pythonhosted.org/packages/41/9f/3500910d5a98549e3098807493851eeef2b89cdd3032227558a104dfe926/json5-0.12.0-py3-none-any.whl.metadata\n",
      "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.24.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/e7/9c/0e6afc12c269578be5c0c1c9f4b49a8d32770a080260c333ac04cc1c832d/soupsieve-2.7-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for sniffio>=1.1 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for argon2-cffi-bindings from https://files.pythonhosted.org/packages/37/2c/e34e47c7dee97ba6f01a6203e0383e15b60fb85d78ac9a15cd066f6fe28b/argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.26.0)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for python-json-logger>=2.0.4 from https://files.pythonhosted.org/packages/08/20/0f2523b9e50a8052bc6a8b732dfc8568abbdc42010aef03a2d750bdab3b2/python_json_logger-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for rfc3339-validator from https://files.pythonhosted.org/packages/7b/44/4e421b96b67b2daff264473f7465db72fbdf36a07e05494f50300cc7b0c6/rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for rfc3986-validator>=0.1.1 from https://files.pythonhosted.org/packages/9e/51/17023c0f8f1869d8806b979a2bffa3f861f26a3f1a66b094288323fba52f/rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Collecting fqdn (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for fqdn from https://files.pythonhosted.org/packages/cf/58/8acf1b3e91c58313ce5cb67df61001fc9dcd21be4fadb76c1a2d540e09ed/fqdn-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for isoduration from https://files.pythonhosted.org/packages/7b/55/e5326141505c5d5e34c5e0935d2908a74e4561eca44108fbfb9c13d2911a/isoduration-20.11.0-py3-none-any.whl.metadata\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jsonpointer>1.13 from https://files.pythonhosted.org/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for uri-template from https://files.pythonhosted.org/packages/e7/00/3fca040d7cf8a32776d3d81a00c8ee7457e00f80c649f1e4a863c8321ae9/uri_template-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for webcolors>=24.6.0 from https://files.pythonhosted.org/packages/60/e8/c0e05e4684d13459f93d312077a9a2efbe04d59c393bc2b8802248c908d4/webcolors-24.11.1-py3-none-any.whl.metadata\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for cffi>=1.0.1 from https://files.pythonhosted.org/packages/50/b9/db34c4755a7bd1cb2d1603ac3863f22bcecbd1ba29e5ee841a4bc510b294/cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for pycparser from https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl.metadata\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for arrow>=0.15.0 from https://files.pythonhosted.org/packages/f8/ed/e97229a566617f2ae958a6b13e7cc0f585470eac730a73e9e82c32a3cdd2/arrow-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for types-python-dateutil>=2.8.10 from https://files.pythonhosted.org/packages/72/52/43e70a8e57fefb172c22a21000b03ebcc15e47e97f5cb8495b9c2832efb4/types_python_dateutil-2.9.0.20250708-py3-none-any.whl.metadata\n",
      "  Downloading types_python_dateutil-2.9.0.20250708-py3-none-any.whl.metadata (1.9 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "   ---------------------------------------- 0.0/494.8 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 122.9/494.8 kB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 317.4/494.8 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 494.8/494.8 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.7.1-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.4/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/8.7 MB 4.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/8.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.1/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.3/8.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.5/8.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.7/8.7 MB 5.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.0/8.7 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.2/8.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.5/8.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.7/8.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.0/8.7 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.3/8.7 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.6/8.7 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.9/8.7 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.1/8.7 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.5/8.7 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.8/8.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.1/8.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.7 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.9/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.1/8.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.5/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.9/8.7 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.1/8.7 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.7 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 294.9/294.9 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "   ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 68.0/68.0 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.3/116.3 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "   ---------------------------------------- 0.0/193.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 193.6/193.6 kB 12.2 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 307.7/307.7 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "   ---------------------------------------- 0.0/146.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 146.7/146.7 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/26.2 MB 8.9 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.7/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.1/26.2 MB 8.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.5/26.2 MB 8.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.9/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.3/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.8/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.1/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.5/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.9/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.4/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.8/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.2/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.7/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.1/26.2 MB 8.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.3/26.2 MB 9.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.7/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 7.1/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.6/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.0/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.5/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.9/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.3/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.8/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.0/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.3/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.7/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.1/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.6/26.2 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.9/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.3/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.7/26.2 MB 8.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.2/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.6/26.2 MB 8.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.0/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.5/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.9/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.3/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.8/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.2/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.6/26.2 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.1/26.2 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.5/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.0/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.4/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.8/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.3/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.7/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.2/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.6/26.2 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.0/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.2 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.9/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.3/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.2/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.7/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.5/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.0/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.8/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.8/64.8 kB ? eta 0:00:00\n",
      "Downloading scipy-1.16.0-cp312-cp312-win_amd64.whl (38.4 MB)\n",
      "   ---------------------------------------- 0.0/38.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.4 MB 6.3 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.5/38.4 MB 4.7 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.9/38.4 MB 6.0 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.3/38.4 MB 6.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.8/38.4 MB 7.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.2/38.4 MB 7.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.6/38.4 MB 8.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.1/38.4 MB 8.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.5/38.4 MB 8.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.9/38.4 MB 8.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.4/38.4 MB 8.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.8/38.4 MB 8.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.2/38.4 MB 8.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.7/38.4 MB 8.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.1/38.4 MB 8.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.6/38.4 MB 8.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.0/38.4 MB 8.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.4/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 7.9/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.3/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 8.7/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.2/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 9.6/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.0/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.5/38.4 MB 9.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 10.9/38.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.3/38.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 11.8/38.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.2/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 12.6/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.1/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 13.5/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.0/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.4/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 14.8/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.3/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 15.7/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.2/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 16.6/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.1/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 17.5/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.0/38.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.4/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.7/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.9/38.4 MB 9.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.2/38.4 MB 9.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.7/38.4 MB 9.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.1/38.4 MB 9.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.6/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.5/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.9/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.3/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.2/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.6/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.1/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.5/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.0/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.4/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.8/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.3/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.7/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.1/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.6/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.0/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.5/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 28.9/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.3/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.8/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.2/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.6/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.1/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.5/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 31.9/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.4/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 32.8/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.2/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 33.7/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.1/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.5/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.0/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.4/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.8/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.6/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.0/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.1/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.5/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.9/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.4/38.4 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.8/139.8 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading jupyterlab-4.4.4-py3-none-any.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.3 MB 12.5 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/12.3 MB 10.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/12.3 MB 10.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/12.3 MB 9.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.1/12.3 MB 9.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.3 MB 9.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.0/12.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.5/12.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.9/12.3 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.3/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.7/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.2/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.6/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.0/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.5/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.9/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.3/12.3 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.8/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.2/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.6/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.1/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.5/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.0/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.4/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 0.0/258.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 258.5/258.5 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading notebook-7.4.4-py3-none-any.whl (14.3 MB)\n",
      "   ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/14.3 MB 11.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/14.3 MB 10.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.0/14.3 MB 8.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.4/14.3 MB 8.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.9/14.3 MB 8.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.3/14.3 MB 8.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.7/14.3 MB 8.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.2/14.3 MB 8.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/14.3 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.1/14.3 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.6/14.3 MB 9.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.0/14.3 MB 9.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.6/14.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.0/14.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.6/14.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.1/14.3 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.6/14.3 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.0/14.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.5/14.3 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.0/14.3 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.6/14.3 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.1/14.3 MB 9.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.6/14.3 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.1/14.3 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.7/14.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.2/14.3 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.8/14.3 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.3/14.3 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.3 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.3/14.3 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl (449 kB)\n",
      "   ---------------------------------------- 0.0/449.3 kB ? eta -:--:--\n",
      "   ---------------------------------------  440.3/449.3 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 449.3/449.3 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.8/78.8 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading jupyter_lsp-2.2.6-py3-none-any.whl (69 kB)\n",
      "   ---------------------------------------- 0.0/69.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 69.4/69.4 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
      "   ---------------------------------------- 0.0/386.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 386.9/386.9 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.7/59.7 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "   ---------------------------------------- 0.0/216.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 216.6/216.6 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading mistune-3.1.3-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.4/53.4 kB ? eta 0:00:00\n",
      "Downloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 13.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.2 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "   ---------------------------------------- 0.0/187.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 187.3/187.3 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.9/100.9 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/10.2 MB 8.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/10.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.5/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/10.2 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.5/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.1/10.2 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.7/10.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.2/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.6/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.7/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.3/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.8/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.3/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.4/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.8/10.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.9/43.9 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
      "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.7/58.7 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading pywinpty-2.0.15-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.4 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.0/1.4 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
      "Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.7/86.7 kB ? eta 0:00:00\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "   ---------------------------------------- 0.0/163.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 163.4/163.4 kB 10.2 MB/s eta 0:00:00\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/182.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 182.0/182.0 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.4/66.4 kB ? eta 0:00:00\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 117.6/117.6 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading types_python_dateutil-2.9.0.20250708-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: webencodings, xxhash, widgetsnbextension, websocket-client, webcolors, uri-template, types-python-dateutil, tinycss2, threadpoolctl, soupsieve, sniffio, send2trash, scipy, rfc3986-validator, rfc3339-validator, requests, pywinpty, python-json-logger, pycparser, pyarrow, propcache, prometheus-client, pandocfilters, overrides, multidict, mistune, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, joblib, h11, fsspec, frozenlist, fqdn, dill, defusedxml, bleach, babel, async-lru, aiohappyeyeballs, yarl, terminado, scikit-learn, multiprocess, kagglehub, httpcore, cffi, beautifulsoup4, arrow, anyio, aiosignal, seaborn, jupyter-server-terminals, isoduration, ipywidgets, httpx, argon2-cffi-bindings, aiohttp, jupyter-console, argon2-cffi, nbclient, jupyter-events, datasets, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 anyio-4.9.0 argon2-cffi-25.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.5 babel-2.17.0 beautifulsoup4-4.13.4 bleach-6.2.0 cffi-1.17.1 datasets-4.0.0 defusedxml-0.7.1 dill-0.3.8 fqdn-1.5.1 frozenlist-1.7.0 fsspec-2025.3.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ipywidgets-8.1.7 isoduration-20.11.0 joblib-1.5.1 json5-0.12.0 jsonpointer-3.0.0 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.6 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.4 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 kagglehub-0.3.12 mistune-3.1.3 multidict-6.6.3 multiprocess-0.70.16 nbclient-0.10.2 nbconvert-7.16.6 notebook-7.4.4 notebook-shim-0.2.4 overrides-7.7.0 pandocfilters-1.5.1 prometheus-client-0.22.1 propcache-0.3.2 pyarrow-21.0.0 pycparser-2.22 python-json-logger-3.3.0 pywinpty-2.0.15 requests-2.32.4 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 scikit-learn-1.7.1 scipy-1.16.0 seaborn-0.13.2 send2trash-1.8.3 sniffio-1.3.1 soupsieve-2.7 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 types-python-dateutil-2.9.0.20250708 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# First install required libraries if not already done\n",
    "!pip install transformers datasets scikit-learn torch pandas matplotlib seaborn jupyter kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce449cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"ankurzing/sentiment-analysis-for-financial-news\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Define file path\n",
    "file_path = os.path.join(path, \"all-data.csv\")\n",
    "\n",
    "# Read CSV with no header and proper encoding\n",
    "df = pd.read_csv(file_path, engine='python', sep=',', header=None, encoding='latin-1')\n",
    "\n",
    "# Check the first few rows to understand column order\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Assign column names manually based on inspection\n",
    "# Based on public dataset info, it's usually [sentiment, text]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Now filter valid labels\n",
    "valid_labels = {'positive', 'neutral', 'negative'}\n",
    "df['label'] = df['label'].str.strip()\n",
    "df = df[df['label'].isin(valid_labels)]\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: print shapes\n",
    "print(\"\\nTrain shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"  # FinBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Convert pandas DataFrames to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Define your label mappings correctly (only the valid ones)\n",
    "labels = ['positive', 'neutral', 'negative']\n",
    "\n",
    "# Create mappings\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Map string labels to integers within the tokenization function\n",
    "    # Ensure examples['label'] is a string before mapping\n",
    "    label_str = examples[\"label\"]\n",
    "    examples[\"labels\"] = label2id[label_str]\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=False)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "# Remove the original 'label' column as we now have 'labels'\n",
    "tokenized_train = tokenized_train.remove_columns([\"label\"])\n",
    "tokenized_test = tokenized_test.remove_columns([\"label\"])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels), # Use len(labels) to be dynamic\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finbert-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"finbert-finetuned-final\")\n",
    "tokenizer.save_pretrained(\"finbert-finetuned-final\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "true_labels = tokenized_test[\"labels\"]\n",
    "\n",
    "# Define the list of all possible labelsac\n",
    "all_labels = list(label2id.values())\n",
    "\n",
    "# Print report\n",
    "print(classification_report(true_labels, preds, target_names=label2id.keys(), labels=all_labels, zero_division=0))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(true_labels, preds, labels=all_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label2id.keys())\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"FinBERT Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 1. Load your custom model\n",
    "model_path = \"finbert-finetuned-final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# 2. Fetch news from FMP with proper error handling\n",
    "def fetch_news(symbol, api_key, days=3730):\n",
    "    cutoff = datetime.utcnow() - timedelta(days=days)\n",
    "    all_articles = []\n",
    "    page = 0\n",
    "\n",
    "    while True:\n",
    "        url = f\"https://financialmodelingprep.com/api/v3/stock_news?symbol={symbol}&page={page}&apikey={api_key}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            news = response.json()\n",
    "\n",
    "            if not news:\n",
    "                break  # No more articles\n",
    "\n",
    "            # Filter articles by date\n",
    "            page_articles = []\n",
    "            for article in news:\n",
    "                try:\n",
    "                    article_date = datetime.strptime(article['publishedDate'], \"%Y-%m-%d %H:%M:%S\")\n",
    "                    if article_date < cutoff:\n",
    "                        continue  # Skip articles older than cutoff\n",
    "                    page_articles.append(article)\n",
    "                except (KeyError, ValueError):\n",
    "                    continue\n",
    "\n",
    "            all_articles.extend(page_articles)\n",
    "\n",
    "            # Check if we've reached the cutoff date\n",
    "            if len(page_articles) < len(news):\n",
    "                break  # This page contained articles beyond cutoff date\n",
    "\n",
    "            page += 1\n",
    "\n",
    "            # Safety limit to prevent infinite loops\n",
    "            if page > 50:  # Max 50 pages (50,000 articles)\n",
    "                print(\"Reached maximum page limit\")\n",
    "                break\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching page {page}: {e}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Found {len(all_articles)} articles within {days} days\")\n",
    "    return all_articles\n",
    "\n",
    "# 3. Analyze sentiment with YOUR model\n",
    "def analyze_sentiment(articles):\n",
    "    results = []\n",
    "    for art in articles:\n",
    "        try:\n",
    "            # Use title if content is missing\n",
    "            text = art.get('content', art.get('title', ''))\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            inputs = tokenizer(text,\n",
    "                              return_tensors=\"pt\",\n",
    "                              truncation=True,\n",
    "                              max_length=512)\n",
    "            with torch.no_grad():\n",
    "                logits = model(**inputs).logits\n",
    "            probs = torch.softmax(logits, dim=1)[0]\n",
    "\n",
    "            results.append({\n",
    "                'date': datetime.strptime(art['publishedDate'], \"%Y-%m-%d %H:%M:%S\").date(),\n",
    "                'sentiment': probs[0].item() - probs[2].item(),  # positive - negative\n",
    "                'title': art['title'],\n",
    "                'source': art.get('site', 'Unknown')\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article '{art.get('title', '')}': {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 4. Fetch stock prices with error handling\n",
    "def fetch_prices(symbol, api_key):\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{symbol}?apikey={api_key}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Check if response contains historical data\n",
    "        if 'historical' not in data:\n",
    "            print(f\"No price data found: {data}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        prices = pd.DataFrame(data['historical'])\n",
    "        prices['date'] = pd.to_datetime(prices['date'])\n",
    "        return prices[['date', 'close']]\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch prices: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 5. Main workflow\n",
    "API_KEY = \"API_KEY\"  # Replace with your actual API key\n",
    "SYMBOL = \"AAPL\"\n",
    "\n",
    "# Fetch and process data\n",
    "print(\"Fetching news...\")\n",
    "news = fetch_news(SYMBOL, API_KEY, days=3507)\n",
    "print(f\"Found {len(news)} articles\")\n",
    "\n",
    "print(\"Analyzing sentiment...\")\n",
    "sentiment_df = analyze_sentiment(news)\n",
    "print(f\"Processed {len(sentiment_df)} articles\")\n",
    "\n",
    "print(\"Fetching stock prices...\")\n",
    "prices_df = fetch_prices(SYMBOL, API_KEY)\n",
    "print(f\"Found {len(prices_df)} price records\")\n",
    "\n",
    "if sentiment_df.empty or prices_df.empty:\n",
    "    print(\"Insufficient data for visualization\")\n",
    "else:\n",
    "    # Aggregate daily sentiment\n",
    "    daily_sentiment = sentiment_df.groupby('date')['sentiment'].mean().reset_index()\n",
    "    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "\n",
    "    # Merge with prices\n",
    "    merged_df = pd.merge(\n",
    "        prices_df,\n",
    "        daily_sentiment,\n",
    "        on='date',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Filter to the period where we have sentiment data\n",
    "    sentiment_start = daily_sentiment['date'].min()\n",
    "    sentiment_end = daily_sentiment['date'].max()\n",
    "    chart_start = sentiment_start - timedelta(days=30)\n",
    "    chart_end = sentiment_end + timedelta(days=5)\n",
    "\n",
    "    filtered_df = merged_df[\n",
    "        (merged_df['date'] >= chart_start) &\n",
    "        (merged_df['date'] <= chart_end)\n",
    "    ]\n",
    "\n",
    "    # Fill missing sentiment with 0 (neutral)\n",
    "    filtered_df['sentiment'].fillna(0, inplace=True)\n",
    "\n",
    "    # Add rolling average for sentiment\n",
    "    filtered_df['sentiment_ma'] = filtered_df['sentiment'].rolling(7, min_periods=1).mean()\n",
    "\n",
    "    # 6. Visualization - single plot with dual axes\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    # Plot stock prices\n",
    "    ax1.plot(filtered_df['date'], filtered_df['close'], 'b-', linewidth=2, label='Stock Price')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Stock Price', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.set_title(f'{SYMBOL} Stock Price vs. News Sentiment')\n",
    "\n",
    "    # Create second axis for sentiment\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot sentiment rolling average\n",
    "    ax2.plot(filtered_df['date'], filtered_df['sentiment_ma'],\n",
    "            'r-', linewidth=2,\n",
    "            label='7-day Sentiment Avg')\n",
    "    ax2.set_ylabel('Sentiment Score (7-day MA)', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "\n",
    "    # Add horizontal line at 0 for neutral sentiment\n",
    "    ax2.axhline(0, color='gray', linestyle='--', linewidth=0.8, label='Neutral')\n",
    "\n",
    "    # Add markers for the actual sentiment period\n",
    "    ax2.axvline(sentiment_start, color='g', linestyle=':', alpha=0.7, label='Sentiment Start')\n",
    "    ax2.axvline(sentiment_end, color='r', linestyle=':', alpha=0.7, label='Sentiment End')\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Show sample of the most positive/negative news\n",
    "    print(\"\\nTop 3 Positive News:\")\n",
    "    print(sentiment_df.nlargest(3, 'sentiment')[['date', 'title', 'sentiment']])\n",
    "\n",
    "    print(\"\\nTop 3 Negative News:\")\n",
    "    print(sentiment_df.nsmallest(3, 'sentiment')[['date', 'title', 'sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Required columns check ---\n",
    "required_price_cols = {'date', 'close'}\n",
    "required_sentiment_cols = {'date', 'sentiment'}\n",
    "\n",
    "if prices_df.empty or sentiment_df.empty:\n",
    "    raise ValueError(\"Error: One or both of the input DataFrames (prices_df, sentiment_df) are empty.\")\n",
    "\n",
    "if not required_price_cols.issubset(prices_df.columns):\n",
    "    raise ValueError(f\"Error: prices_df is missing required columns: {required_price_cols - set(prices_df.columns)}\")\n",
    "\n",
    "if not required_sentiment_cols.issubset(sentiment_df.columns):\n",
    "    raise ValueError(f\"Error: sentiment_df is missing required columns: {required_sentiment_cols - set(sentiment_df.columns)}\")\n",
    "\n",
    "# --- Convert date columns and inspect ---\n",
    "prices_df['date'] = pd.to_datetime(prices_df['date'])\n",
    "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
    "\n",
    "print(\"Latest price date:\", prices_df['date'].max().date())\n",
    "print(\"Latest sentiment date:\", sentiment_df['date'].max().date())\n",
    "\n",
    "# --- Merge DataFrames ---\n",
    "sentiment_daily = sentiment_df.groupby('date')['sentiment'].mean().reset_index()\n",
    "merged_df = pd.merge(prices_df, sentiment_daily, on='date', how='left')\n",
    "merged_df['sentiment'] = merged_df['sentiment'].fillna(0)\n",
    "\n",
    "if merged_df.empty:\n",
    "    raise ValueError(\"Error: Merged DataFrame is empty.\")\n",
    "if merged_df['close'].isnull().all():\n",
    "    raise ValueError(\"Error: All close prices are NaN after merge.\")\n",
    "\n",
    "# --- Compute indicators ---\n",
    "def compute_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def prepare_df(df):\n",
    "    df = df.copy()\n",
    "    df['sentiment_ma'] = df['sentiment'].rolling(7, min_periods=1).mean()\n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['sma_5'] = df['close'].rolling(5).mean()\n",
    "    df['rsi'] = compute_rsi(df['close'])\n",
    "    df.ffill(inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = prepare_df(merged_df)\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(\"Last date in df before forecast:\", df['date'].iloc[-1].date())\n",
    "\n",
    "# --- Generate features ---\n",
    "def make_features(df, lookback=5):\n",
    "    scaler = MinMaxScaler()\n",
    "    features = ['close', 'sentiment_ma', 'returns', 'sma_5', 'rsi']\n",
    "    data = scaler.fit_transform(df[features])\n",
    "    \n",
    "    X, y, date_out = [], [], []\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    for i in range(lookback, len(df)):\n",
    "        X.append(data[i-lookback:i])\n",
    "        y.append(data[i, 0])\n",
    "        date_out.append(df['date'].iloc[i])\n",
    "        \n",
    "    return np.array(X), np.array(y), scaler, pd.Series(date_out).reset_index(drop=True)\n",
    "\n",
    "X, y, scaler, dates = make_features(df)\n",
    "\n",
    "if len(X) == 0 or len(y) == 0:\n",
    "    raise ValueError(\"Error: Not enough data after lookback window.\")\n",
    "\n",
    "# --- LSTM model ---\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden=50):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "# --- Training ---\n",
    "def train_model(X, y):\n",
    "    X, y = torch.tensor(X).float(), torch.tensor(y).float().view(-1, 1)\n",
    "    tr_len = int(0.8 * len(X))\n",
    "    X_tr, y_tr, X_te, y_te = X[:tr_len], y[:tr_len], X[tr_len:], y[tr_len:]\n",
    "    model = StockLSTM(X.shape[2])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for e in range(50):\n",
    "        model.train(); optimizer.zero_grad()\n",
    "        loss = loss_fn(model(X_tr), y_tr)\n",
    "        loss.backward(); optimizer.step()\n",
    "        if e % 10 == 0:\n",
    "            print(f\"Epoch {e}, Loss: {loss.item():.4f}\")\n",
    "    return model, model(X_te).detach().numpy(), y_te.numpy(), X_te\n",
    "\n",
    "model, preds, actual, X_test = train_model(X, y)\n",
    "\n",
    "# --- Forecasting ---\n",
    "def forecast_days(model, seq, days, n_feat, scaler):\n",
    "    preds = []\n",
    "    for _ in range(days):\n",
    "        with torch.no_grad():\n",
    "            val = model(torch.tensor(seq).float().unsqueeze(0)).item()\n",
    "        padded = np.array([[val] + [0]*(n_feat-1)])\n",
    "        unscaled = scaler.inverse_transform(padded)[0,0]\n",
    "        preds.append(unscaled)\n",
    "        seq = np.vstack([seq[1:], padded])\n",
    "    return preds\n",
    "\n",
    "forecast = forecast_days(model, X[-1], 7, X.shape[2], scaler)\n",
    "forecast_start = df['date'].iloc[-1] + timedelta(days=1)\n",
    "\n",
    "print(\"Forecasting starts from:\", forecast_start.date())\n",
    "print(\"\\nForecast for Next 7 Days:\")\n",
    "for i, val in enumerate(forecast):\n",
    "    print(f\"{(forecast_start + timedelta(days=i)).date()}: ${val:.2f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "# SYMBOL is from previous cell\n",
    "a_inv = scaler.inverse_transform(np.hstack([actual.reshape(-1,1), np.zeros((len(actual), X.shape[2]-1))]))[:,0]\n",
    "p_inv = scaler.inverse_transform(np.hstack([preds, np.zeros((len(preds), X.shape[2]-1))]))[:,0]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(dates[-len(a_inv):], a_inv, label=\"Actual\")\n",
    "plt.plot(dates[-len(p_inv):], p_inv, label=\"Predicted\")\n",
    "plt.title(f\"{SYMBOL} - LSTM Forecast (Latest data: {df['date'].iloc[-1].date()})\")\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Price\")\n",
    "plt.xticks(rotation=45); plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28f1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2c600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ankurzing/sentiment-analysis-for-financial-news?dataset_version_number=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 903k/903k [00:00<00:00, 3.37MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\User\\.cache\\kagglehub\\datasets\\ankurzing\\sentiment-analysis-for-financial-news\\versions\\5\n",
      "First 5 rows:\n",
      "          0                                                  1\n",
      "0   neutral  According to Gran , the company has no plans t...\n",
      "1   neutral  Technopolis plans to develop in stages an area...\n",
      "2  negative  The international electronic industry company ...\n",
      "3  positive  With the new production plant the company woul...\n",
      "4  positive  According to the company 's updated strategy f...\n",
      "\n",
      "Train shape: (3876, 2)\n",
      "Test shape: (970, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d566d97819e489dbcf70ec28d37511a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MQSMaster\\mqs\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--yiyanghkust--finbert-tone. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ef6b6243794ce3ad5c30a81b29b884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'positive': 0, 'neutral': 1, 'negative': 2}\n",
      "id2label: {0: 'positive', 1: 'neutral', 2: 'negative'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ade142e5b44bd3ab2212507b64d418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3876 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07756606610545749f8af40cfa686c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bd9a97bc1a4b84896994aa6c16fa25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     70\u001b[39m tokenized_test = tokenized_test.remove_columns([\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     72\u001b[39m model = AutoModelForSequenceClassification.from_pretrained(\n\u001b[32m     73\u001b[39m     model_name,\n\u001b[32m     74\u001b[39m     num_labels=\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;66;03m# Use len(labels) to be dynamic\u001b[39;00m\n\u001b[32m     75\u001b[39m     id2label=id2label,\n\u001b[32m     76\u001b[39m     label2id=label2id\n\u001b[32m     77\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfinbert-finetuned\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m18\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m18\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtensorboard\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madamw_torch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#  corrected scheduler\u001b[39;49;00m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m trainer = Trainer(\n\u001b[32m    103\u001b[39m     model=model,\n\u001b[32m    104\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m     compute_metrics=compute_metrics,    \u001b[38;5;66;03m#  here\u001b[39;00m\n\u001b[32m    109\u001b[39m )\n\u001b[32m    112\u001b[39m trainer.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:133\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, hub_revision, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, liger_kernel_config, eval_use_gather_object, average_tokens_across_devices)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\MQSMaster\\mqs\\Lib\\site-packages\\transformers\\training_args.py:1790\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[32m   1793\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.average_tokens_across_devices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\MQSMaster\\mqs\\Lib\\site-packages\\transformers\\training_args.py:2319\u001b[39m, in \u001b[36mTrainingArguments.device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2315\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2316\u001b[39m \u001b[33;03mThe device used by this process.\u001b[39;00m\n\u001b[32m   2317\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2318\u001b[39m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_devices\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\MQSMaster\\mqs\\Lib\\site-packages\\transformers\\utils\\generic.py:67\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, objtype)\u001b[39m\n\u001b[32m     65\u001b[39m cached = \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\MQSMaster\\mqs\\Lib\\site-packages\\transformers\\training_args.py:2189\u001b[39m, in \u001b[36mTrainingArguments._setup_devices\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[32m   2188\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m2189\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   2190\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2191\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2192\u001b[39m         )\n\u001b[32m   2193\u001b[39m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[32m   2194\u001b[39m accelerator_state_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = {\u001b[33m\"\u001b[39m\u001b[33menabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33muse_configured_state\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[31mImportError\u001b[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6119caeaca1a4995a7eb454e72067f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"ankurzing/sentiment-analysis-for-financial-news\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Define file path\n",
    "file_path = os.path.join(path, \"all-data.csv\")\n",
    "\n",
    "# Read CSV with no header and proper encoding\n",
    "df = pd.read_csv(file_path, engine='python', sep=',', header=None, encoding='latin-1')\n",
    "\n",
    "# Check the first few rows to understand column order\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Assign column names manually based on inspection\n",
    "# Based on public dataset info, it's usually [sentiment, text]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Now filter valid labels\n",
    "valid_labels = {'positive', 'neutral', 'negative'}\n",
    "df['label'] = df['label'].str.strip()\n",
    "df = df[df['label'].isin(valid_labels)]\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: print shapes\n",
    "print(\"\\nTrain shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"  # FinBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Convert pandas DataFrames to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Define your label mappings correctly (only the valid ones)\n",
    "labels = ['positive', 'neutral', 'negative']\n",
    "\n",
    "# Create mappings\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Map string labels to integers within the tokenization function\n",
    "    # Ensure examples['label'] is a string before mapping\n",
    "    label_str = examples[\"label\"]\n",
    "    examples[\"labels\"] = label2id[label_str]\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=False)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "# Remove the original 'label' column as we now have 'labels'\n",
    "tokenized_train = tokenized_train.remove_columns([\"label\"])\n",
    "tokenized_test = tokenized_test.remove_columns([\"label\"])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels), # Use len(labels) to be dynamic\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finbert-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=18,\n",
    "    per_device_eval_batch_size=18,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"linear\",  #  corrected scheduler\n",
    "    warmup_steps=500,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,    #  here\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"finbert-finetuned-final\")\n",
    "tokenizer.save_pretrained(\"finbert-finetuned-final\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mqs (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
