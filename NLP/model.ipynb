{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987a54b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (4.53.2)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/eb/62/eb8157afb21bd229c864521c1ab4fa8e9b4f1b06bafdd8c4668a7a31b5dd/datasets-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/15/fa/c61a787e35f05f17fc10523f567677ec4eeee5f95aa4798dbbbcd9625617/scikit_learn-1.7.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.7.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (3.10.3)\n",
      "Collecting seaborn\n",
      "  Obtaining dependency information for seaborn from https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl.metadata\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jupyter\n",
      "  Obtaining dependency information for jupyter from https://files.pythonhosted.org/packages/38/64/285f20a31679bf547b75602702f7800e74dbabae36ef324f716c02804753/jupyter-1.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting kagglehub\n",
      "  Obtaining dependency information for kagglehub from https://files.pythonhosted.org/packages/49/bf/c2a24567bb6bd80c1fe7cb2ed1a332666476f69c313256aff96094bef93e/kagglehub-0.3.12-py3-none-any.whl.metadata\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Obtaining dependency information for pyarrow>=15.0.0 from https://files.pythonhosted.org/packages/71/30/f3795b6e192c3ab881325ffe172e526499eb3780e306a15103a2764916a2/pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Obtaining dependency information for dill<0.3.9,>=0.3.0 from https://files.pythonhosted.org/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl.metadata\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/7c/e4/56027c4a6b4ae70ca9de302488c5ca95ad4a39e190093d6c1a8ace08341b/requests-2.32.4-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/d9/6b/1c443fe6cfeb4ad1dcf231cdec96eb94fb43d6498b4469ed8b51f8b59a37/xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Obtaining dependency information for multiprocess<0.70.17 from https://files.pythonhosted.org/packages/0a/7d/a988f258104dcd2ccf1ed40fdc97e26c4ac351eeaf81d76e266c52d84e2f/multiprocess-0.70.16-py312-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<=2025.3.0,>=2023.1.0 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]<=2025.3.0,>=2023.1.0 from https://files.pythonhosted.org/packages/56/53/eb690efa8513166adef3e0669afd31e95ffde69fb3c52ec2ac7223ed6018/fsspec-2025.3.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Obtaining dependency information for scipy>=1.8.0 from https://files.pythonhosted.org/packages/ea/b5/29fece1a74c6a94247f8a6fb93f5b28b533338e9c34fdcc9cfe7a939a767/scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.16.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/7d/4f/1195bbac8e0c2acc5f740661631d8d750dc38d4a32b23ee5df3cde6f4e0d/joblib-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Collecting notebook (from jupyter)\n",
      "  Obtaining dependency information for notebook from https://files.pythonhosted.org/packages/b3/c0/e64d2047fd752249b0b69f6aee2a7049eb94e7273e5baabc8b8ad05cc068/notebook-7.4.4-py3-none-any.whl.metadata\n",
      "  Downloading notebook-7.4.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Obtaining dependency information for jupyter-console from https://files.pythonhosted.org/packages/ca/77/71d78d58f15c22db16328a476426f7ac4a60d3a5a7ba3b9627ee2f7903d4/jupyter_console-6.6.3-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Obtaining dependency information for nbconvert from https://files.pythonhosted.org/packages/cc/9a/cd673b2f773a12c992f41309ef81b99da1690426bd2f96957a7ade0d3ed7/nbconvert-7.16.6-py3-none-any.whl.metadata\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter) (6.29.5)\n",
      "Collecting ipywidgets (from jupyter)\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/58/6a/9166369a2f092bd286d24e6307de555d63616e8ddb373ebad2b5635ca4cd/ipywidgets-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Obtaining dependency information for jupyterlab from https://files.pythonhosted.org/packages/f8/82/66910ce0995dbfdb33609f41c99fe32ce483b9624a3e7d672af14ff63b9f/jupyterlab-4.4.4-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab-4.4.4-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for aiohttp!=4.0.0a0,!=4.0.0a1 from https://files.pythonhosted.org/packages/98/d5/7ac2464aebd2eecac38dbe96148c9eb487679c512449ba5215d233755582/aiohttp-3.12.14-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (9.4.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter)\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.14 from https://files.pythonhosted.org/packages/ca/51/5447876806d1088a0f8f71e16542bf350918128d0a69437df26047c8e46f/widgetsnbextension-4.0.14-py3-none-any.whl.metadata\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter)\n",
      "  Obtaining dependency information for jupyterlab_widgets~=3.0.15 from https://files.pythonhosted.org/packages/43/6a/ca128561b22b60bd5a0c4ea26649e68c8556b82bc70a0c396eebc977fe86/jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter-console->jupyter) (3.0.51)\n",
      "Requirement already satisfied: pygments in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter-console->jupyter) (2.19.2)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for async-lru>=1.0.0 from https://files.pythonhosted.org/packages/03/49/d10027df9fce941cb8184e78a02857af36360d33e1721df81c5ed2179a1a/async_lru-2.0.5-py3-none-any.whl.metadata\n",
      "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for httpx>=0.25.0 from https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyter-lsp>=2.0.0 from https://files.pythonhosted.org/packages/47/7c/12f68daf85b469b4896d5e4a629baa33c806d61de75ac5b39d8ef27ec4a2/jupyter_lsp-2.2.6-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_lsp-2.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyter-server<3,>=2.4.0 from https://files.pythonhosted.org/packages/46/1f/5ebbced977171d09a7b0c08a285ff9a20aafb9c51bde07e52349ff1ddd71/jupyter_server-2.16.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyterlab-server<3,>=2.27.1 from https://files.pythonhosted.org/packages/54/09/2032e7d15c544a0e3cd831c51d77a8ca57f7555b2e1b2922142eddb02a84/jupyterlab_server-2.27.3-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
      "  Obtaining dependency information for notebook-shim>=0.2 from https://files.pythonhosted.org/packages/f9/33/bd5b9137445ea4b680023eb0469b2bb969d61303dedb2aac6560ff3d14a1/notebook_shim-0.2.4-py3-none-any.whl.metadata\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for beautifulsoup4 from https://files.pythonhosted.org/packages/50/cd/30110dc0ffcf3b131156077b90e9f60ed75711223f306da4db08eff8403b/beautifulsoup4-4.13.4-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach[css]!=5.0.0 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for bleach[css]!=5.0.0 from https://files.pythonhosted.org/packages/fc/55/96142937f66150805c25c4d0f31ee4132fd33497753400734f9dfdcbdc66/bleach-6.2.0-py3-none-any.whl.metadata\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for defusedxml from https://files.pythonhosted.org/packages/07/6c/aa3f2f849e01cb6a001cd8554a88d4c77c5c1a31c95bdf1cf9301e6d9ef4/defusedxml-0.7.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for jupyterlab-pygments from https://files.pythonhosted.org/packages/b1/dd/ead9d8ea85bf202d90cc513b533f9c363121c7792674f78e0d8a854b63b4/jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for mistune<4,>=2.0.3 from https://files.pythonhosted.org/packages/01/4d/23c4e4f09da849e127e9f123241946c23c1e30f45a88366879e064211815/mistune-3.1.3-py3-none-any.whl.metadata\n",
      "  Downloading mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for nbclient>=0.5.0 from https://files.pythonhosted.org/packages/34/6d/e7fa07f03a4a7b221d94b4d586edb754a9b0dc3c9e2c93353e9fa4e0d117/nbclient-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
      "  Obtaining dependency information for pandocfilters>=1.4.1 from https://files.pythonhosted.org/packages/ef/af/4fbc8cab944db5d21b7e2a5b8e9211a03a79852b1157e2c102fcc61ac440/pandocfilters-1.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.5.0 from https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for aiosignal>=1.4.0 from https://files.pythonhosted.org/packages/fb/76/641ae371508676492379f16e2fa48f4e2c11741bd63c48be4b12a6b09cba/aiosignal-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/0b/15/c026e9a9fc17585a9d461f65d8593d281fedf55fbf7eb53f16c6df2392f9/frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/6a/a3/0fbc7afdf7cb1aa12a086b02959307848eb6bcc8f66fcb66c0cb57e2a2c1/multidict-6.6.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/19/61/d582be5d226cf79071681d1b46b848d6cb03d7b70af7063e33a2787eaa03/propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/eb/83/5d9092950565481b413b31a23e75dd3418ff0a277d6e0abf3729d4d1ce25/yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "     ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 76.3/76.3 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting webencodings (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Obtaining dependency information for webencodings from https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Obtaining dependency information for tinycss2<1.5,>=1.1.0 from https://files.pythonhosted.org/packages/e6/34/ebdc18bae6aa14fbee1a08b63c015c72b64868ff7dae68808ab500c492e2/tinycss2-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for anyio from https://files.pythonhosted.org/packages/a1/ee/48ca1a7c89ffec8b6a0c5d02b89c305671d5ffd8d3c94acf8b8c408575bb/anyio-4.9.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for h11>=0.16 from https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (310)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for argon2-cffi>=21.1 from https://files.pythonhosted.org/packages/4f/d3/a8b22fa575b297cd6e3e3b0155c7e25db170edf1c74783d6a31a2490b8d9/argon2_cffi-25.1.0-py3-none-any.whl.metadata\n",
      "  Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyter-events>=0.11.0 from https://files.pythonhosted.org/packages/e2/48/577993f1f99c552f18a0428731a755e06171f9902fa118c379eb7c04ea22/jupyter_events-0.12.0-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jupyter-server-terminals>=0.4.4 from https://files.pythonhosted.org/packages/07/2d/2b32cdbe8d2a602f697a649798554e4f072115438e92249624e532e8aca6/jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for overrides>=5.0 from https://files.pythonhosted.org/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl.metadata\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for prometheus-client>=0.9 from https://files.pythonhosted.org/packages/32/ae/ec06af4fe3ee72d16973474f122541746196aaa16cea6f66d18b963c6177/prometheus_client-0.22.1-py3-none-any.whl.metadata\n",
      "  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pywinpty>=2.0.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for pywinpty>=2.0.1 from https://files.pythonhosted.org/packages/88/e5/9714def18c3a411809771a3fbcec70bffa764b9675afb00048a620fca604/pywinpty-2.0.15-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pywinpty-2.0.15-cp312-cp312-win_amd64.whl.metadata (5.2 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for send2trash>=1.8.2 from https://files.pythonhosted.org/packages/40/b0/4562db6223154aa4e22f939003cb92514c79f3d4dccca3444253fd17f902/Send2Trash-1.8.3-py3-none-any.whl.metadata\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for terminado>=0.8.3 from https://files.pythonhosted.org/packages/6a/9e/2064975477fdc887e47ad42157e214526dcad8f317a948dee17e1659a62f/terminado-0.18.1-py3-none-any.whl.metadata\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for websocket-client>=1.7 from https://files.pythonhosted.org/packages/5a/84/44687a29792a70e111c5c477230a72c4b957d88d16141199bf9acb7537a3/websocket_client-1.8.0-py3-none-any.whl.metadata\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for babel>=2.10 from https://files.pythonhosted.org/packages/b7/b8/3fe70c75fe32afc4bb507f75563d39bc5642255d1d94f1f23604725780bf/babel-2.17.0-py3-none-any.whl.metadata\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for json5>=0.9.0 from https://files.pythonhosted.org/packages/41/9f/3500910d5a98549e3098807493851eeef2b89cdd3032227558a104dfe926/json5-0.12.0-py3-none-any.whl.metadata\n",
      "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.24.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/e7/9c/0e6afc12c269578be5c0c1c9f4b49a8d32770a080260c333ac04cc1c832d/soupsieve-2.7-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for sniffio>=1.1 from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for argon2-cffi-bindings from https://files.pythonhosted.org/packages/37/2c/e34e47c7dee97ba6f01a6203e0383e15b60fb85d78ac9a15cd066f6fe28b/argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.26.0)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for python-json-logger>=2.0.4 from https://files.pythonhosted.org/packages/08/20/0f2523b9e50a8052bc6a8b732dfc8568abbdc42010aef03a2d750bdab3b2/python_json_logger-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for rfc3339-validator from https://files.pythonhosted.org/packages/7b/44/4e421b96b67b2daff264473f7465db72fbdf36a07e05494f50300cc7b0c6/rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for rfc3986-validator>=0.1.1 from https://files.pythonhosted.org/packages/9e/51/17023c0f8f1869d8806b979a2bffa3f861f26a3f1a66b094288323fba52f/rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\desktop\\mqsmaster\\mqs\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Collecting fqdn (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for fqdn from https://files.pythonhosted.org/packages/cf/58/8acf1b3e91c58313ce5cb67df61001fc9dcd21be4fadb76c1a2d540e09ed/fqdn-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for isoduration from https://files.pythonhosted.org/packages/7b/55/e5326141505c5d5e34c5e0935d2908a74e4561eca44108fbfb9c13d2911a/isoduration-20.11.0-py3-none-any.whl.metadata\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for jsonpointer>1.13 from https://files.pythonhosted.org/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for uri-template from https://files.pythonhosted.org/packages/e7/00/3fca040d7cf8a32776d3d81a00c8ee7457e00f80c649f1e4a863c8321ae9/uri_template-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for webcolors>=24.6.0 from https://files.pythonhosted.org/packages/60/e8/c0e05e4684d13459f93d312077a9a2efbe04d59c393bc2b8802248c908d4/webcolors-24.11.1-py3-none-any.whl.metadata\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for cffi>=1.0.1 from https://files.pythonhosted.org/packages/50/b9/db34c4755a7bd1cb2d1603ac3863f22bcecbd1ba29e5ee841a4bc510b294/cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for pycparser from https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl.metadata\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for arrow>=0.15.0 from https://files.pythonhosted.org/packages/f8/ed/e97229a566617f2ae958a6b13e7cc0f585470eac730a73e9e82c32a3cdd2/arrow-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Obtaining dependency information for types-python-dateutil>=2.8.10 from https://files.pythonhosted.org/packages/72/52/43e70a8e57fefb172c22a21000b03ebcc15e47e97f5cb8495b9c2832efb4/types_python_dateutil-2.9.0.20250708-py3-none-any.whl.metadata\n",
      "  Downloading types_python_dateutil-2.9.0.20250708-py3-none-any.whl.metadata (1.9 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "   ---------------------------------------- 0.0/494.8 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 122.9/494.8 kB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 317.4/494.8 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 494.8/494.8 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.7.1-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.4/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/8.7 MB 4.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/8.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.1/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.3/8.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.5/8.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.7/8.7 MB 5.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.0/8.7 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.2/8.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.5/8.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.7/8.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.0/8.7 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.3/8.7 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.6/8.7 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.9/8.7 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.1/8.7 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.5/8.7 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.8/8.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.1/8.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.7 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.9/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.1/8.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.5/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.9/8.7 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.1/8.7 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.7 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 294.9/294.9 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "   ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 68.0/68.0 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.3/116.3 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "   ---------------------------------------- 0.0/193.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 193.6/193.6 kB 12.2 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 307.7/307.7 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "   ---------------------------------------- 0.0/146.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 146.7/146.7 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/26.2 MB 8.9 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.7/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.1/26.2 MB 8.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.5/26.2 MB 8.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.9/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.3/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.8/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.1/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.5/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.9/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.4/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.8/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.2/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.7/26.2 MB 8.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.1/26.2 MB 8.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.3/26.2 MB 9.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.7/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 7.1/26.2 MB 8.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.6/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.0/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.5/26.2 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.9/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.3/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.8/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.0/26.2 MB 8.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.3/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.7/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.1/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.6/26.2 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.9/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.3/26.2 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.7/26.2 MB 8.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.2/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.6/26.2 MB 8.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.0/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.5/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.9/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.3/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.8/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.2/26.2 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.6/26.2 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.1/26.2 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.5/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.0/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.4/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.8/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.3/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.7/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.2/26.2 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.6/26.2 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.0/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.2 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.9/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.3/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.2/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.7/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.5/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.0/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.8/26.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.8/64.8 kB ? eta 0:00:00\n",
      "Downloading scipy-1.16.0-cp312-cp312-win_amd64.whl (38.4 MB)\n",
      "   ---------------------------------------- 0.0/38.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.4 MB 6.3 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.5/38.4 MB 4.7 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.9/38.4 MB 6.0 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.3/38.4 MB 6.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.8/38.4 MB 7.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.2/38.4 MB 7.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.6/38.4 MB 8.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.1/38.4 MB 8.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.5/38.4 MB 8.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.9/38.4 MB 8.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.4/38.4 MB 8.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.8/38.4 MB 8.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.2/38.4 MB 8.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.7/38.4 MB 8.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.1/38.4 MB 8.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.6/38.4 MB 8.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.0/38.4 MB 8.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.4/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 7.9/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 8.3/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 8.7/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.2/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 9.6/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.0/38.4 MB 9.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.5/38.4 MB 9.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 10.9/38.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.3/38.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 11.8/38.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.2/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 12.6/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.1/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 13.5/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.0/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.4/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 14.8/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.3/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 15.7/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.2/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 16.6/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.1/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 17.5/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.0/38.4 MB 9.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.4/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.7/38.4 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.9/38.4 MB 9.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.2/38.4 MB 9.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.7/38.4 MB 9.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.1/38.4 MB 9.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.6/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.5/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.9/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.3/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.2/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.6/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.1/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.5/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.0/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.4/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.8/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.3/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.7/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.1/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.6/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.0/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.5/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 28.9/38.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.3/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.8/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.2/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.6/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.1/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.5/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 31.9/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.4/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 32.8/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.2/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 33.7/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.1/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.5/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.0/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.4/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.8/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.6/38.4 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.0/38.4 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.1/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.5/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.9/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.4/38.4 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.8/139.8 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading jupyterlab-4.4.4-py3-none-any.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.3 MB 12.5 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/12.3 MB 10.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/12.3 MB 10.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/12.3 MB 9.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.1/12.3 MB 9.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.3 MB 9.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.0/12.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.5/12.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.9/12.3 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.3/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.7/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.2/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.6/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.0/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.5/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.9/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.3/12.3 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.8/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.2/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.6/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.1/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.5/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.0/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.4/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 0.0/258.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 258.5/258.5 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading notebook-7.4.4-py3-none-any.whl (14.3 MB)\n",
      "   ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/14.3 MB 11.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/14.3 MB 10.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.0/14.3 MB 8.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.4/14.3 MB 8.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.9/14.3 MB 8.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.3/14.3 MB 8.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.7/14.3 MB 8.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.2/14.3 MB 8.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/14.3 MB 9.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.1/14.3 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.6/14.3 MB 9.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.0/14.3 MB 9.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.6/14.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.0/14.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.6/14.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.1/14.3 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.6/14.3 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.0/14.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.5/14.3 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.0/14.3 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.6/14.3 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.1/14.3 MB 9.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.6/14.3 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.1/14.3 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.7/14.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.2/14.3 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.8/14.3 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.3/14.3 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.3 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.3/14.3 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl (449 kB)\n",
      "   ---------------------------------------- 0.0/449.3 kB ? eta -:--:--\n",
      "   ---------------------------------------  440.3/449.3 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 449.3/449.3 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.8/78.8 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading jupyter_lsp-2.2.6-py3-none-any.whl (69 kB)\n",
      "   ---------------------------------------- 0.0/69.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 69.4/69.4 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
      "   ---------------------------------------- 0.0/386.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 386.9/386.9 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.7/59.7 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "   ---------------------------------------- 0.0/216.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 216.6/216.6 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading mistune-3.1.3-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.4/53.4 kB ? eta 0:00:00\n",
      "Downloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 13.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.2 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "   ---------------------------------------- 0.0/187.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 187.3/187.3 kB 11.8 MB/s eta 0:00:00\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "   ---------------------------------------- 0.0/100.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 100.9/100.9 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/10.2 MB 8.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/10.2 MB 10.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.5/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/10.2 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.5/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.1/10.2 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.7/10.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.2/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.6/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.7/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.3/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.8/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.3/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.4/10.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.8/10.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.9/43.9 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
      "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.7/58.7 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading pywinpty-2.0.15-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.4 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.0/1.4 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
      "Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.7/86.7 kB ? eta 0:00:00\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "   ---------------------------------------- 0.0/163.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 163.4/163.4 kB 10.2 MB/s eta 0:00:00\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/182.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 182.0/182.0 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "   ---------------------------------------- 0.0/66.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 66.4/66.4 kB ? eta 0:00:00\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 117.6/117.6 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading types_python_dateutil-2.9.0.20250708-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: webencodings, xxhash, widgetsnbextension, websocket-client, webcolors, uri-template, types-python-dateutil, tinycss2, threadpoolctl, soupsieve, sniffio, send2trash, scipy, rfc3986-validator, rfc3339-validator, requests, pywinpty, python-json-logger, pycparser, pyarrow, propcache, prometheus-client, pandocfilters, overrides, multidict, mistune, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, joblib, h11, fsspec, frozenlist, fqdn, dill, defusedxml, bleach, babel, async-lru, aiohappyeyeballs, yarl, terminado, scikit-learn, multiprocess, kagglehub, httpcore, cffi, beautifulsoup4, arrow, anyio, aiosignal, seaborn, jupyter-server-terminals, isoduration, ipywidgets, httpx, argon2-cffi-bindings, aiohttp, jupyter-console, argon2-cffi, nbclient, jupyter-events, datasets, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 anyio-4.9.0 argon2-cffi-25.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.5 babel-2.17.0 beautifulsoup4-4.13.4 bleach-6.2.0 cffi-1.17.1 datasets-4.0.0 defusedxml-0.7.1 dill-0.3.8 fqdn-1.5.1 frozenlist-1.7.0 fsspec-2025.3.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ipywidgets-8.1.7 isoduration-20.11.0 joblib-1.5.1 json5-0.12.0 jsonpointer-3.0.0 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.6 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.4 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 kagglehub-0.3.12 mistune-3.1.3 multidict-6.6.3 multiprocess-0.70.16 nbclient-0.10.2 nbconvert-7.16.6 notebook-7.4.4 notebook-shim-0.2.4 overrides-7.7.0 pandocfilters-1.5.1 prometheus-client-0.22.1 propcache-0.3.2 pyarrow-21.0.0 pycparser-2.22 python-json-logger-3.3.0 pywinpty-2.0.15 requests-2.32.4 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 scikit-learn-1.7.1 scipy-1.16.0 seaborn-0.13.2 send2trash-1.8.3 sniffio-1.3.1 soupsieve-2.7 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 types-python-dateutil-2.9.0.20250708 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# First install required libraries if not already done\n",
    "!pip install transformers datasets scikit-learn torch pandas matplotlib seaborn jupyter kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce449cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"ankurzing/sentiment-analysis-for-financial-news\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Define file path\n",
    "file_path = os.path.join(path, \"all-data.csv\")\n",
    "\n",
    "# Read CSV with no header and proper encoding\n",
    "df = pd.read_csv(file_path, engine='python', sep=',', header=None, encoding='latin-1')\n",
    "\n",
    "# Check the first few rows to understand column order\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Assign column names manually based on inspection\n",
    "# Based on public dataset info, it's usually [sentiment, text]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Now filter valid labels\n",
    "valid_labels = {'positive', 'neutral', 'negative'}\n",
    "df['label'] = df['label'].str.strip()\n",
    "df = df[df['label'].isin(valid_labels)]\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: print shapes\n",
    "print(\"\\nTrain shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"  # FinBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Convert pandas DataFrames to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Define your label mappings correctly (only the valid ones)\n",
    "labels = ['positive', 'neutral', 'negative']\n",
    "\n",
    "# Create mappings\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Map string labels to integers within the tokenization function\n",
    "    # Ensure examples['label'] is a string before mapping\n",
    "    label_str = examples[\"label\"]\n",
    "    examples[\"labels\"] = label2id[label_str]\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=False)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "# Remove the original 'label' column as we now have 'labels'\n",
    "tokenized_train = tokenized_train.remove_columns([\"label\"])\n",
    "tokenized_test = tokenized_test.remove_columns([\"label\"])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels), # Use len(labels) to be dynamic\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finbert-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"finbert-finetuned-final\")\n",
    "tokenizer.save_pretrained(\"finbert-finetuned-final\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "true_labels = tokenized_test[\"labels\"]\n",
    "\n",
    "# Define the list of all possible labelsac\n",
    "all_labels = list(label2id.values())\n",
    "\n",
    "# Print report\n",
    "print(classification_report(true_labels, preds, target_names=label2id.keys(), labels=all_labels, zero_division=0))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(true_labels, preds, labels=all_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label2id.keys())\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"FinBERT Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 1. Load your custom model\n",
    "model_path = \"finbert-finetuned-final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# 2. Fetch news from FMP with proper error handling\n",
    "def fetch_news(symbol, api_key, days=3730):\n",
    "    cutoff = datetime.utcnow() - timedelta(days=days)\n",
    "    all_articles = []\n",
    "    page = 0\n",
    "\n",
    "    while True:\n",
    "        url = f\"https://financialmodelingprep.com/api/v3/stock_news?symbol={symbol}&page={page}&apikey={api_key}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            news = response.json()\n",
    "\n",
    "            if not news:\n",
    "                break  # No more articles\n",
    "\n",
    "            # Filter articles by date\n",
    "            page_articles = []\n",
    "            for article in news:\n",
    "                try:\n",
    "                    article_date = datetime.strptime(article['publishedDate'], \"%Y-%m-%d %H:%M:%S\")\n",
    "                    if article_date < cutoff:\n",
    "                        continue  # Skip articles older than cutoff\n",
    "                    page_articles.append(article)\n",
    "                except (KeyError, ValueError):\n",
    "                    continue\n",
    "\n",
    "            all_articles.extend(page_articles)\n",
    "\n",
    "            # Check if we've reached the cutoff date\n",
    "            if len(page_articles) < len(news):\n",
    "                break  # This page contained articles beyond cutoff date\n",
    "\n",
    "            page += 1\n",
    "\n",
    "            # Safety limit to prevent infinite loops\n",
    "            if page > 50:  # Max 50 pages (50,000 articles)\n",
    "                print(\"Reached maximum page limit\")\n",
    "                break\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching page {page}: {e}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Found {len(all_articles)} articles within {days} days\")\n",
    "    return all_articles\n",
    "\n",
    "# 3. Analyze sentiment with YOUR model\n",
    "def analyze_sentiment(articles):\n",
    "    results = []\n",
    "    for art in articles:\n",
    "        try:\n",
    "            # Use title if content is missing\n",
    "            text = art.get('content', art.get('title', ''))\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            inputs = tokenizer(text,\n",
    "                              return_tensors=\"pt\",\n",
    "                              truncation=True,\n",
    "                              max_length=512)\n",
    "            with torch.no_grad():\n",
    "                logits = model(**inputs).logits\n",
    "            probs = torch.softmax(logits, dim=1)[0]\n",
    "\n",
    "            results.append({\n",
    "                'date': datetime.strptime(art['publishedDate'], \"%Y-%m-%d %H:%M:%S\").date(),\n",
    "                'sentiment': probs[0].item() - probs[2].item(),  # positive - negative\n",
    "                'title': art['title'],\n",
    "                'source': art.get('site', 'Unknown')\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article '{art.get('title', '')}': {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 4. Fetch stock prices with error handling\n",
    "def fetch_prices(symbol, api_key):\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{symbol}?apikey={api_key}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Check if response contains historical data\n",
    "        if 'historical' not in data:\n",
    "            print(f\"No price data found: {data}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        prices = pd.DataFrame(data['historical'])\n",
    "        prices['date'] = pd.to_datetime(prices['date'])\n",
    "        return prices[['date', 'close']]\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch prices: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 5. Main workflow\n",
    "API_KEY = \"API_KEY\"  # Replace with your actual API key\n",
    "SYMBOL = \"AAPL\"\n",
    "\n",
    "# Fetch and process data\n",
    "print(\"Fetching news...\")\n",
    "news = fetch_news(SYMBOL, API_KEY, days=3507)\n",
    "print(f\"Found {len(news)} articles\")\n",
    "\n",
    "print(\"Analyzing sentiment...\")\n",
    "sentiment_df = analyze_sentiment(news)\n",
    "print(f\"Processed {len(sentiment_df)} articles\")\n",
    "\n",
    "print(\"Fetching stock prices...\")\n",
    "prices_df = fetch_prices(SYMBOL, API_KEY)\n",
    "print(f\"Found {len(prices_df)} price records\")\n",
    "\n",
    "if sentiment_df.empty or prices_df.empty:\n",
    "    print(\"Insufficient data for visualization\")\n",
    "else:\n",
    "    # Aggregate daily sentiment\n",
    "    daily_sentiment = sentiment_df.groupby('date')['sentiment'].mean().reset_index()\n",
    "    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "\n",
    "    # Merge with prices\n",
    "    merged_df = pd.merge(\n",
    "        prices_df,\n",
    "        daily_sentiment,\n",
    "        on='date',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Filter to the period where we have sentiment data\n",
    "    sentiment_start = daily_sentiment['date'].min()\n",
    "    sentiment_end = daily_sentiment['date'].max()\n",
    "    chart_start = sentiment_start - timedelta(days=30)\n",
    "    chart_end = sentiment_end + timedelta(days=5)\n",
    "\n",
    "    filtered_df = merged_df[\n",
    "        (merged_df['date'] >= chart_start) &\n",
    "        (merged_df['date'] <= chart_end)\n",
    "    ]\n",
    "\n",
    "    # Fill missing sentiment with 0 (neutral)\n",
    "    filtered_df['sentiment'].fillna(0, inplace=True)\n",
    "\n",
    "    # Add rolling average for sentiment\n",
    "    filtered_df['sentiment_ma'] = filtered_df['sentiment'].rolling(7, min_periods=1).mean()\n",
    "\n",
    "    # 6. Visualization - single plot with dual axes\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    # Plot stock prices\n",
    "    ax1.plot(filtered_df['date'], filtered_df['close'], 'b-', linewidth=2, label='Stock Price')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Stock Price', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.set_title(f'{SYMBOL} Stock Price vs. News Sentiment')\n",
    "\n",
    "    # Create second axis for sentiment\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot sentiment rolling average\n",
    "    ax2.plot(filtered_df['date'], filtered_df['sentiment_ma'],\n",
    "            'r-', linewidth=2,\n",
    "            label='7-day Sentiment Avg')\n",
    "    ax2.set_ylabel('Sentiment Score (7-day MA)', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "\n",
    "    # Add horizontal line at 0 for neutral sentiment\n",
    "    ax2.axhline(0, color='gray', linestyle='--', linewidth=0.8, label='Neutral')\n",
    "\n",
    "    # Add markers for the actual sentiment period\n",
    "    ax2.axvline(sentiment_start, color='g', linestyle=':', alpha=0.7, label='Sentiment Start')\n",
    "    ax2.axvline(sentiment_end, color='r', linestyle=':', alpha=0.7, label='Sentiment End')\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Show sample of the most positive/negative news\n",
    "    print(\"\\nTop 3 Positive News:\")\n",
    "    print(sentiment_df.nlargest(3, 'sentiment')[['date', 'title', 'sentiment']])\n",
    "\n",
    "    print(\"\\nTop 3 Negative News:\")\n",
    "    print(sentiment_df.nsmallest(3, 'sentiment')[['date', 'title', 'sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Required columns check ---\n",
    "required_price_cols = {'date', 'close'}\n",
    "required_sentiment_cols = {'date', 'sentiment'}\n",
    "\n",
    "if prices_df.empty or sentiment_df.empty:\n",
    "    raise ValueError(\"Error: One or both of the input DataFrames (prices_df, sentiment_df) are empty.\")\n",
    "\n",
    "if not required_price_cols.issubset(prices_df.columns):\n",
    "    raise ValueError(f\"Error: prices_df is missing required columns: {required_price_cols - set(prices_df.columns)}\")\n",
    "\n",
    "if not required_sentiment_cols.issubset(sentiment_df.columns):\n",
    "    raise ValueError(f\"Error: sentiment_df is missing required columns: {required_sentiment_cols - set(sentiment_df.columns)}\")\n",
    "\n",
    "# --- Convert date columns and inspect ---\n",
    "prices_df['date'] = pd.to_datetime(prices_df['date'])\n",
    "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
    "\n",
    "print(\"Latest price date:\", prices_df['date'].max().date())\n",
    "print(\"Latest sentiment date:\", sentiment_df['date'].max().date())\n",
    "\n",
    "# --- Merge DataFrames ---\n",
    "sentiment_daily = sentiment_df.groupby('date')['sentiment'].mean().reset_index()\n",
    "merged_df = pd.merge(prices_df, sentiment_daily, on='date', how='left')\n",
    "merged_df['sentiment'] = merged_df['sentiment'].fillna(0)\n",
    "\n",
    "if merged_df.empty:\n",
    "    raise ValueError(\"Error: Merged DataFrame is empty.\")\n",
    "if merged_df['close'].isnull().all():\n",
    "    raise ValueError(\"Error: All close prices are NaN after merge.\")\n",
    "\n",
    "# --- Compute indicators ---\n",
    "def compute_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def prepare_df(df):\n",
    "    df = df.copy()\n",
    "    df['sentiment_ma'] = df['sentiment'].rolling(7, min_periods=1).mean()\n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['sma_5'] = df['close'].rolling(5).mean()\n",
    "    df['rsi'] = compute_rsi(df['close'])\n",
    "    df.ffill(inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = prepare_df(merged_df)\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(\"Last date in df before forecast:\", df['date'].iloc[-1].date())\n",
    "\n",
    "# --- Generate features ---\n",
    "def make_features(df, lookback=5):\n",
    "    scaler = MinMaxScaler()\n",
    "    features = ['close', 'sentiment_ma', 'returns', 'sma_5', 'rsi']\n",
    "    data = scaler.fit_transform(df[features])\n",
    "    \n",
    "    X, y, date_out = [], [], []\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    for i in range(lookback, len(df)):\n",
    "        X.append(data[i-lookback:i])\n",
    "        y.append(data[i, 0])\n",
    "        date_out.append(df['date'].iloc[i])\n",
    "        \n",
    "    return np.array(X), np.array(y), scaler, pd.Series(date_out).reset_index(drop=True)\n",
    "\n",
    "X, y, scaler, dates = make_features(df)\n",
    "\n",
    "if len(X) == 0 or len(y) == 0:\n",
    "    raise ValueError(\"Error: Not enough data after lookback window.\")\n",
    "\n",
    "# --- LSTM model ---\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden=50):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "# --- Training ---\n",
    "def train_model(X, y):\n",
    "    X, y = torch.tensor(X).float(), torch.tensor(y).float().view(-1, 1)\n",
    "    tr_len = int(0.8 * len(X))\n",
    "    X_tr, y_tr, X_te, y_te = X[:tr_len], y[:tr_len], X[tr_len:], y[tr_len:]\n",
    "    model = StockLSTM(X.shape[2])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for e in range(50):\n",
    "        model.train(); optimizer.zero_grad()\n",
    "        loss = loss_fn(model(X_tr), y_tr)\n",
    "        loss.backward(); optimizer.step()\n",
    "        if e % 10 == 0:\n",
    "            print(f\"Epoch {e}, Loss: {loss.item():.4f}\")\n",
    "    return model, model(X_te).detach().numpy(), y_te.numpy(), X_te\n",
    "\n",
    "model, preds, actual, X_test = train_model(X, y)\n",
    "\n",
    "# --- Forecasting ---\n",
    "def forecast_days(model, seq, days, n_feat, scaler):\n",
    "    preds = []\n",
    "    for _ in range(days):\n",
    "        with torch.no_grad():\n",
    "            val = model(torch.tensor(seq).float().unsqueeze(0)).item()\n",
    "        padded = np.array([[val] + [0]*(n_feat-1)])\n",
    "        unscaled = scaler.inverse_transform(padded)[0,0]\n",
    "        preds.append(unscaled)\n",
    "        seq = np.vstack([seq[1:], padded])\n",
    "    return preds\n",
    "\n",
    "forecast = forecast_days(model, X[-1], 7, X.shape[2], scaler)\n",
    "forecast_start = df['date'].iloc[-1] + timedelta(days=1)\n",
    "\n",
    "print(\"Forecasting starts from:\", forecast_start.date())\n",
    "print(\"\\nForecast for Next 7 Days:\")\n",
    "for i, val in enumerate(forecast):\n",
    "    print(f\"{(forecast_start + timedelta(days=i)).date()}: ${val:.2f}\")\n",
    "\n",
    "# --- Plotting ---\n",
    "# SYMBOL is from previous cell\n",
    "a_inv = scaler.inverse_transform(np.hstack([actual.reshape(-1,1), np.zeros((len(actual), X.shape[2]-1))]))[:,0]\n",
    "p_inv = scaler.inverse_transform(np.hstack([preds, np.zeros((len(preds), X.shape[2]-1))]))[:,0]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(dates[-len(a_inv):], a_inv, label=\"Actual\")\n",
    "plt.plot(dates[-len(p_inv):], p_inv, label=\"Predicted\")\n",
    "plt.title(f\"{SYMBOL} - LSTM Forecast (Latest data: {df['date'].iloc[-1].date()})\")\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Price\")\n",
    "plt.xticks(rotation=45); plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28f1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"ankurzing/sentiment-analysis-for-financial-news\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Define file path\n",
    "file_path = os.path.join(path, \"all-data.csv\")\n",
    "\n",
    "# Read CSV with no header and proper encoding\n",
    "df = pd.read_csv(file_path, engine='python', sep=',', header=None, encoding='latin-1')\n",
    "\n",
    "# Check the first few rows to understand column order\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Assign column names manually based on inspection\n",
    "# Based on public dataset info, it's usually [sentiment, text]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Now filter valid labels\n",
    "valid_labels = {'positive', 'neutral', 'negative'}\n",
    "df['label'] = df['label'].str.strip()\n",
    "df = df[df['label'].isin(valid_labels)]\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: print shapes\n",
    "print(\"\\nTrain shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"  # FinBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Convert pandas DataFrames to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Define your label mappings correctly (only the valid ones)\n",
    "labels = ['positive', 'neutral', 'negative']\n",
    "\n",
    "# Create mappings\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Map string labels to integers within the tokenization function\n",
    "    # Ensure examples['label'] is a string before mapping\n",
    "    label_str = examples[\"label\"]\n",
    "    examples[\"labels\"] = label2id[label_str]\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=False)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "# Remove the original 'label' column as we now have 'labels'\n",
    "tokenized_train = tokenized_train.remove_columns([\"label\"])\n",
    "tokenized_test = tokenized_test.remove_columns([\"label\"])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels), # Use len(labels) to be dynamic\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finbert-finetuned\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=18,\n",
    "    per_device_eval_batch_size=18,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"linear\",  #  corrected scheduler\n",
    "    warmup_steps=500,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,    #  here\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"finbert-finetuned-final\")\n",
    "tokenizer.save_pretrained(\"finbert-finetuned-final\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip & download your saved model folder in Colab\n",
    "\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Define the correct directory name\n",
    "directory_to_zip = \"finbert-base-model\"\n",
    "\n",
    "# 1. Make a .zip archive of the saved model directory\n",
    "shutil.make_archive(\n",
    "    base_name=directory_to_zip,  # The name for the output .zip file\n",
    "    format=\"zip\",\n",
    "    root_dir=directory_to_zip    # The folder you want to zip\n",
    ")\n",
    "\n",
    "# 2. Download it to your local machine\n",
    "print(f\" Archiving complete. Downloading {directory_to_zip}.zip...\")\n",
    "files.download(f\"{directory_to_zip}.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mqs (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
